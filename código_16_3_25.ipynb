{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# C√≥digo para el entrenamiento del modelo YOLOv8 ( n, s, m, l, x)"
      ],
      "metadata": {
        "id": "QeczupJOY2_d"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G60lb_jPlMfO"
      },
      "source": [
        "# 0. Memoria ram y capacidad de memoria\n",
        "\n",
        "Vamos a comprobar que memoria ram y capacidad estamos usando en Colab"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JUJ72Ly0lMVO"
      },
      "outputs": [],
      "source": [
        "from psutil import virtual_memory\n",
        "ram_gb = virtual_memory().total / 1e9\n",
        "print('Your runtime has {:.1f} gigabytes of available RAM\\n'.format(ram_gb))\n",
        "\n",
        "if ram_gb < 20:\n",
        "  print('Not using a high-RAM runtime')\n",
        "else:\n",
        "  print('You are using a high-RAM runtime!')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "brkDhF4FkqVw"
      },
      "source": [
        "# 1. Chequear si tengo GPU y cual"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "x3jfFCX2hAbC",
        "outputId": "51010350-d78f-4593-bc79-eb0ff035e81a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/bin/bash: line 1: nvidia-smi: command not found\n"
          ]
        }
      ],
      "source": [
        "gpu_info = !nvidia-smi\n",
        "gpu_info = '\\n'.join(gpu_info)\n",
        "if gpu_info.find('failed') >= 0:\n",
        "  print('Not connected to a GPU')\n",
        "else:\n",
        "  print(gpu_info)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JzV1b5ejlXNJ"
      },
      "source": [
        "# 2. Importar librer√≠as\n",
        "\n",
        "Importamos librer√≠as importantes para el proceso"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#0. En Colab, primero instala los paquetes y monta tu Drive:  Instalar las librer√≠as necesarias\n",
        "!pip install ultralytics wandb  # Esto instalar√° ultralytics y wandb (torch y torchvision generalmente ya vienen instalados en Colab)\n",
        "\n",
        "import ultralytics\n",
        "ultralytics.checks()"
      ],
      "metadata": {
        "id": "vBN6CVOMXMzJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c7ca7085-62c3-45da-e00c-d125e01ff442"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ultralytics 8.3.90 üöÄ Python-3.11.11 torch-2.6.0+cu124 CPU (Intel Xeon 2.20GHz)\n",
            "Setup complete ‚úÖ (2 CPUs, 12.7 GB RAM, 40.9/225.8 GB disk)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3. Conectar con Google Drive"
      ],
      "metadata": {
        "id": "QJMCCI_LYfjh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Montar Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')           #cambiar la ruta de drive de donde lo extraes"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z1vapCDQYiOL",
        "outputId": "b56f3879-363f-4e4c-e933-e8be59ad63a4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#4. Importar archivos"
      ],
      "metadata": {
        "id": "99bBCzLUbUPp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4.1  Importar carpetas desde Google Drive si no est√°n en Rar"
      ],
      "metadata": {
        "id": "3wWN1qGYaYPp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# 2. Definir las carpetas en Google Drive que deseas importar\n",
        "# Por ejemplo, si tienes dos carpetas: una para im√°genes y otra para etiquetas\n",
        "folders_to_copy = [\n",
        "    \"/content/drive/MyDrive/model_rar_640_tiles_labels/Fotos_elegidas\"  # Carpeta con im√°genes\n",
        "   # \"/content/drive/MyDrive/Tmodel_rar_640_tiles_labels/fotos_elegidas/labels\"   # Carpeta con archivos txt\n",
        "]\n",
        "\n",
        "# 3. Definir un directorio de destino en Colab donde copiar√°s estas carpetas\n",
        "destination_base = \"/content/dataset_importado_bueno\"\n",
        "import os\n",
        "os.makedirs(destination_base, exist_ok=True)\n",
        "\n",
        "# 4. Copiar cada carpeta desde Drive al directorio local\n",
        "for folder in folders_to_copy:\n",
        "    folder_name = os.path.basename(folder)\n",
        "    dest = os.path.join(destination_base, folder_name)\n",
        "    # El comando cp -r copia recursivamente la carpeta\n",
        "    !cp -r \"{folder}\" \"{dest}\"\n",
        "\n",
        "# 5. Verificar que se copiaron las carpetas\n",
        "!ls -l \"{destination_base}\""
      ],
      "metadata": {
        "id": "lGgKCEFWbTLI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#4.2.  Descomprimir archivos rar de Drive a Google collab directamente si est√°n en rar"
      ],
      "metadata": {
        "id": "MriKZEjdXmHn"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VyZmo2KIlfU1"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "# 2. Instalar unrar para poder descomprimir archivos RAR\n",
        "!apt-get update\n",
        "!apt-get install -y unrar\n",
        "\n",
        "\n",
        "\n",
        "# 4. Definir las rutas de los archivos RAR en Drive\n",
        "# Ajusta estas rutas seg√∫n d√≥nde est√©n ubicados en tu Drive\n",
        "images_train_rar = \"/content/drive/MyDrive/model_rar_640_tiles_labels/train/images.rar\"\n",
        "labels_train_rar = \"/content/drive/MyDrive/model_rar_640_tiles_labels/train/labels.rar\"\n",
        "images_validation_rar = \"/content/drive/MyDrive/model_rar_640_tiles_labels/valid/images.rar\"\n",
        "labels_validation_rar = \"/content/drive/MyDrive/model_rar_640_tiles_labels//valid/labels.rar\"\n",
        "\n",
        "# 5. Definir las carpetas de destino en Colab para cada uno\n",
        "# Estas carpetas mantendr√°n la estructura de YOLO (por ejemplo, \"images\" y \"labels\")\n",
        "dest_train_images = \"/content/dataset/train\"    # he dejado image sy labels en el mismo directorio a ver si as√≠ se apa√±a el no detectar labels\n",
        "dest_train_labels = \"/content/dataset/train\"\n",
        "dest_val_images = \"/content/dataset/val\"\n",
        "dest_val_labels = \"/content/dataset/val\"\n",
        "\n",
        "import os\n",
        "os.makedirs(dest_train_images, exist_ok=True)\n",
        "os.makedirs(dest_train_labels, exist_ok=True)\n",
        "os.makedirs(dest_val_images, exist_ok=True)\n",
        "os.makedirs(dest_val_labels, exist_ok=True)\n",
        "\n",
        "# 6. Descomprimir cada archivo RAR en su carpeta correspondiente\n",
        "!unrar x \"{images_train_rar}\" \"{dest_train_images}/\"\n",
        "!unrar x \"{labels_train_rar}\" \"{dest_train_labels}/\"\n",
        "!unrar x \"{images_validation_rar}\" \"{dest_val_images}/\"\n",
        "!unrar x \"{labels_validation_rar}\" \"{dest_val_labels}/\"\n",
        "\n",
        "# Opcional: listar el contenido para confirmar que se descomprimi√≥ correctamente\n",
        "!ls /content/dataset/train/       # he dejado image sy labels en el mismo directorio a ver si as√≠ se apa√±a el no detectar labels\n",
        "!ls /content/dataset/train/\n",
        "!ls /content/dataset/val/\n",
        "!ls /content/dataset/val/\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#5. OVERSAMPLING:\n",
        "\n",
        "Aplicamos oversampling a aquellas fotos con etiquetas .\n",
        "\n",
        "Aqu√≠ elegimos cuantas copias de nuestra foto orginal queremos producir.\n",
        "\n",
        "El objetivo es aumentar el n√∫mero de fotos positivas solo para poder tener m√°s que ense√±ar.\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "gj4aQDS9NtJ3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import shutil\n",
        "\n",
        "# Rutas de las carpetas originales\n",
        "orig_images_dir = \"/content/drive/MyDrive/Fotos_elegidas/train/images.rar\"\n",
        "orig_labels_dir = \"/content/drive/MyDrive/Fotos_elegidas/train/labels\"\n",
        "\n",
        "# Carpeta de destino para el dataset balanceado\n",
        "balanced_dir = \"/content/balanced_train\"\n",
        "balanced_images_dir = os.path.join(balanced_dir, \"images\")\n",
        "balanced_labels_dir = os.path.join(balanced_dir, \"labels\")\n",
        "\n",
        "os.makedirs(balanced_images_dir, exist_ok=True)\n",
        "os.makedirs(balanced_labels_dir, exist_ok=True)\n",
        "\n",
        "################################################################\n",
        "################################################################\n",
        "# Factor de duplicaci√≥n para im√°genes positivas\n",
        "dup_factor = 3                                                      ########cuantas veces las quiero multiplicar\n",
        "\n",
        "#################################################################\n",
        "\n",
        "# Recorremos todas las im√°genes del dataset original\n",
        "for filename in os.listdir(orig_images_dir):\n",
        "    if not filename.lower().endswith(('.jpg','.jpeg','.png')):\n",
        "        continue\n",
        "    # Ruta de la imagen y de la etiqueta correspondiente\n",
        "    orig_img_path = os.path.join(orig_images_dir, filename)\n",
        "    label_filename = os.path.splitext(filename)[0] + \".txt\"\n",
        "    orig_label_path = os.path.join(orig_labels_dir, label_filename)\n",
        "\n",
        "    # Determinar si la imagen es positiva (tiene anotaciones) o negativa\n",
        "    is_positive = False\n",
        "    if os.path.exists(orig_label_path):\n",
        "        with open(orig_label_path, 'r') as f:\n",
        "            content = f.read().strip()\n",
        "        if content:  # Si hay algo, es positiva\n",
        "            is_positive = True\n",
        "\n",
        "    # Copiar la imagen y el archivo de etiqueta al nuevo directorio\n",
        "    # Si es positiva, duplicamos seg√∫n el factor\n",
        "    copies = dup_factor if is_positive else 1\n",
        "    for i in range(copies):\n",
        "        # Para evitar sobreescritura, agregamos un sufijo en el nombre de la imagen duplicada\n",
        "        new_filename = os.path.splitext(filename)[0]\n",
        "        if copies > 1:\n",
        "            new_filename += f\"_{i+1}\"\n",
        "        new_filename += os.path.splitext(filename)[1]\n",
        "        new_img_path = os.path.join(balanced_images_dir, new_filename)\n",
        "        shutil.copy2(orig_img_path, new_img_path)\n",
        "\n",
        "        # Tambi√©n copiamos la etiqueta (si existe), ajustando el nombre\n",
        "        if os.path.exists(orig_label_path):\n",
        "            new_label_filename = os.path.splitext(label_filename)[0]\n",
        "            if copies > 1:\n",
        "                new_label_filename += f\"_{i+1}\"\n",
        "            new_label_filename += \".txt\"\n",
        "            new_label_path = os.path.join(balanced_labels_dir, new_label_filename)\n",
        "            shutil.copy2(orig_label_path, new_label_path)\n",
        "\n",
        "print(\"Dataset balanceado creado en:\", balanced_dir)\n"
      ],
      "metadata": {
        "id": "OQo8bjMaN1y8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#6. DATA AUGMENTATION\n",
        "\n",
        "Solo se aplican a fotos con etiquetas.\n",
        "\n",
        "Produce una imagen para cada transformaci√≥n (mas la original) , por lo que aumentamos el n√∫mero de im√°genes positivas una vez m√°s. Todo incluyendo etiquetas.  \n",
        "\n",
        "Voy a combinar este paso con la data augmentation durante el entrenamiento de YOLO.\n",
        "\n",
        "**IMPORTANTE**\n",
        "Tengo que saber cuantas im√°genes positivas tengo al final y cuantas negativas para poder organizar proporciones\n",
        "\n",
        "\n",
        "**IMPORTANTE**\n",
        "\n",
        "Hay dos formas de aplicar Data augmentation:"
      ],
      "metadata": {
        "id": "9ieORmaSQAmh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#6.0 Data Augmentation m√°s completa\n",
        "\n",
        "Se produce un numero random de imagenes transformadas que incluyes transformaciones aleatorias\n",
        "\n",
        "puedes controlar numero transformaciones, y numero de imagenes generadas\n",
        "\n",
        "todo mas la original y label\n"
      ],
      "metadata": {
        "id": "VGnuX0T25odO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import cv2\n",
        "import albumentations as A\n",
        "import random\n",
        "import shutil\n",
        "\n",
        "def read_yolo_labels(label_path):\n",
        "    \"\"\"\n",
        "    Lee un archivo de etiquetas YOLO y devuelve:\n",
        "    - bboxes: [x_center, y_center, width, height] (normalizados)\n",
        "    - classes: Lista de clases correspondiente a cada bbox\n",
        "    \"\"\"\n",
        "    bboxes = []\n",
        "    classes = []\n",
        "    if os.path.exists(label_path):\n",
        "        with open(label_path, 'r') as f:\n",
        "            for line in f:\n",
        "                parts = line.strip().split()\n",
        "                if len(parts) == 5:\n",
        "                    classes.append(parts[0])\n",
        "                    bbox = list(map(float, parts[1:]))\n",
        "                    bboxes.append(bbox)\n",
        "    return bboxes, classes\n",
        "\n",
        "# 1) Definir una pipeline que escoja aleatoriamente entre 1 y 6 transformaciones\n",
        "#    con replace=True para permitir tupla en 'n'\n",
        "transform_pipeline = A.Compose([\n",
        "    A.SomeOf([\n",
        "        A.HorizontalFlip(p=1.0),  # voltear horizontalmente\n",
        "        A.Rotate(limit=(-5, 5), p=1.0),       # rotaci√≥n aleatoria entre -15¬∞ y +15¬∞\n",
        "        A.Affine(shear=(-5, 5), p=1.0),       # cizallamiento aleatorio entre -15¬∞ y +15¬∞\n",
        "        A.RandomBrightnessContrast(brightness_limit=(-0.1, 0.2),\n",
        "                                   contrast_limit=(-0.1, 0.2),\n",
        "                                   p=1.0),\n",
        "        A.Blur(blur_limit=5, p=1.0),\n",
        "        A.ColorJitter(brightness=0.05,\n",
        "                      contrast=0.05,\n",
        "                      saturation=0.05,\n",
        "                      #hue=0.2,\n",
        "                      p=1.0),\n",
        "    ],\n",
        "####################################################################################################################################\n",
        "####################################################################################################################################\n",
        "    n=(3),        # elige un subconjunto aleatorio de 1 a 6 transformaciones\n",
        "    replace=True),   # <-- IMPORTANTE: as√≠ evitamos la comparaci√≥n n > len(self.transforms)\n",
        "    A.Resize(640, 640)\n",
        "], bbox_params=A.BboxParams(format='yolo', label_fields=['labels']))\n",
        "\n",
        "####################################################################################################################################\n",
        "####################################################################################################################################\n",
        "\n",
        "# Directorios de entrada (donde est√°n tus im√°genes y anotaciones)\n",
        "input_images_dir = \"/content/drive/MyDrive/fotos_pruebas\"\n",
        "input_labels_dir = \"/content/drive/MyDrive/fotos_pruebas\"\n",
        "\n",
        "# Directorios de salida para im√°genes positivas\n",
        "output_images_dir = \"/content/dataset_aug_combined4/positives/images\"\n",
        "output_labels_dir = \"/content/dataset_aug_combined4/positives/labels\"\n",
        "os.makedirs(output_images_dir, exist_ok=True)\n",
        "os.makedirs(output_labels_dir, exist_ok=True)\n",
        "\n",
        "# Directorios de salida para im√°genes negativas\n",
        "output_neg_images_dir = \"/content/dataset_aug_combined4/negatives/images\"\n",
        "output_neg_labels_dir = \"/content/dataset_aug_combined4/negatives/labels\"\n",
        "os.makedirs(output_neg_images_dir, exist_ok=True)\n",
        "os.makedirs(output_neg_labels_dir, exist_ok=True)\n",
        "\n",
        "# 2) Iterar sobre cada imagen\n",
        "for filename in os.listdir(input_images_dir):\n",
        "    if not filename.lower().endswith(('.jpg', '.jpeg', '.png')):\n",
        "        continue\n",
        "\n",
        "    img_path = os.path.join(input_images_dir, filename)\n",
        "    label_filename = os.path.splitext(filename)[0] + \".txt\"\n",
        "    label_path = os.path.join(input_labels_dir, label_filename)\n",
        "\n",
        "    bboxes, classes = read_yolo_labels(label_path)\n",
        "\n",
        "    # 2a) Si no hay anotaciones, se considera \"negativa\"\n",
        "    if len(bboxes) == 0:\n",
        "        # Copiamos la imagen original y un TXT vac√≠o\n",
        "        shutil.copy2(img_path, os.path.join(output_neg_images_dir, filename))\n",
        "        open(os.path.join(output_neg_labels_dir, label_filename), 'w').close()\n",
        "        print(f\"{filename}: No tiene anotaciones. Copiada en negativos.\")\n",
        "        continue\n",
        "\n",
        "    # 2b) Si la imagen es \"positiva\", copiamos la original\n",
        "    shutil.copy2(img_path, os.path.join(output_images_dir, filename))\n",
        "    shutil.copy2(label_path, os.path.join(output_labels_dir, label_filename))\n",
        "\n",
        "####################################################################################################################################\n",
        "####################################################################################################################################\n",
        "\n",
        "    # 3) Generar un n√∫mero aleatorio de im√°genes aumentadas (entre 1 y 10)\n",
        "\n",
        "    num_variants = random.randint(3, 8)\n",
        "\n",
        "####################################################################################################################################\n",
        "####################################################################################################################################\n",
        "    # 4) Crear las variantes\n",
        "    for i in range(num_variants):\n",
        "        # Leer la imagen original en BGR\n",
        "        image_bgr = cv2.imread(img_path)\n",
        "        if image_bgr is None:\n",
        "            print(f\"No se pudo leer {filename}, se omite.\")\n",
        "            continue\n",
        "\n",
        "        # Convertir a RGB para Albumentations\n",
        "        image_rgb = cv2.cvtColor(image_bgr, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "        # Aplicar la pipeline\n",
        "        try:\n",
        "            result = transform_pipeline(\n",
        "                image=image_rgb,\n",
        "                bboxes=bboxes,\n",
        "                labels=classes\n",
        "            )\n",
        "        except Exception as e:\n",
        "            print(f\"Error al aplicar pipeline en {filename}: {e}\")\n",
        "            continue\n",
        "\n",
        "        aug_img_rgb = result[\"image\"]\n",
        "        aug_bboxes = result[\"bboxes\"]\n",
        "\n",
        "        # Convertir de vuelta a BGR para guardar\n",
        "        aug_img_bgr = cv2.cvtColor(aug_img_rgb, cv2.COLOR_RGB2BGR)\n",
        "\n",
        "        # Nuevo nombre de archivo\n",
        "        new_img_name = f\"{os.path.splitext(filename)[0]}_aug{i}.jpg\"\n",
        "        new_label_name = f\"{os.path.splitext(filename)[0]}_aug{i}.txt\"\n",
        "\n",
        "        # Guardar la imagen\n",
        "        cv2.imwrite(os.path.join(output_images_dir, new_img_name), aug_img_bgr)\n",
        "\n",
        "        # Guardar anotaciones en formato YOLO\n",
        "        with open(os.path.join(output_labels_dir, new_label_name), 'w') as f:\n",
        "            for cls, bbox in zip(classes, aug_bboxes):\n",
        "                f.write(f\"{cls} {bbox[0]:.6f} {bbox[1]:.6f} {bbox[2]:.6f} {bbox[3]:.6f}\\n\")\n",
        "\n",
        "    print(f\"Procesada {filename}: generadas {num_variants} variantes.\")\n",
        "\n",
        "print(\"Data augmentation completo.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zT4TOvqI2sJZ",
        "outputId": "6ec3c951-e86b-401a-fbe4-b51549135fdb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Procesada DSC02325.jpg: generadas 10 variantes.\n",
            "Data augmentation completo.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#6.1 Data augmentation total\n",
        "\n",
        "Se produce una imagen por cada transformaci√≥n ( es la que m√°s im√°genes produce)"
      ],
      "metadata": {
        "id": "anriuVMQbx_G"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n1xS4I2mlnth",
        "outputId": "af8c013e-7b66-4b1e-e8af-d3e45d6e6599"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Procesada DSC02325.jpg con todos los pipelines.\n",
            "Data augmentation completo.\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import cv2\n",
        "import albumentations as A\n",
        "import shutil\n",
        "\n",
        "# Funci√≥n para leer anotaciones YOLO\n",
        "def read_yolo_labels(label_path):\n",
        "    bboxes = []\n",
        "    classes = []\n",
        "    if os.path.exists(label_path):\n",
        "        with open(label_path, 'r') as f:\n",
        "            for line in f:\n",
        "                parts = line.strip().split()\n",
        "                if len(parts) == 5:\n",
        "                    classes.append(parts[0])\n",
        "                    bbox = list(map(float, parts[1:]))\n",
        "                    bboxes.append(bbox)\n",
        "    return bboxes, classes\n",
        "\n",
        "\n",
        "######################################################################################\n",
        "######################################################################################\n",
        "\n",
        "#hay dods cosas a cambiar, la p (probabilidad de que ocurra, y los valores entre los que ocurren teniendo en cuenta las data augmentation que pasan en el training)\n",
        "\n",
        "######################################################################################\n",
        "######################################################################################\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "######################################################################################\n",
        "# Solo transformaciones (sin ToTensorV2):\n",
        "######################################################################################\n",
        "\n",
        "pipeline_flip = A.Compose([\n",
        "    A.HorizontalFlip(p=1.0),\n",
        "    A.Resize(640, 640)\n",
        "], bbox_params=A.BboxParams(format='yolo', label_fields=['labels']))\n",
        "\n",
        "pipeline_rotate = A.Compose([\n",
        "    A.Rotate(limit=5, p=1.0),\n",
        "    A.Resize(640, 640)\n",
        "], bbox_params=A.BboxParams(format='yolo', label_fields=['labels']))\n",
        "\n",
        "pipeline_shear = A.Compose([\n",
        "    A.Affine(shear=5, p=1.0),\n",
        "    A.Resize(640, 640)\n",
        "], bbox_params=A.BboxParams(format='yolo', label_fields=['labels']))\n",
        "\n",
        "pipeline_bright_contrast = A.Compose([\n",
        "    A.RandomBrightnessContrast(brightness_limit=(0, 0.2), contrast_limit=(0, 0.2), p=0.5),\n",
        "    A.Resize(640, 640)\n",
        "], bbox_params=A.BboxParams(format='yolo', label_fields=['labels']))\n",
        "\n",
        "pipeline_blur = A.Compose([\n",
        "    A.Blur(blur_limit=5, p=1.0),\n",
        "    A.Resize(640, 640)\n",
        "], bbox_params=A.BboxParams(format='yolo', label_fields=['labels']))\n",
        "\n",
        "pipeline_no_aug = A.Compose([\n",
        "    A.Resize(640, 640)\n",
        "], bbox_params=A.BboxParams(format='yolo', label_fields=['labels']))\n",
        "\n",
        "######################################################################################\n",
        "# NUEVO PIPELINE: Ajuste de brillo, contraste, saturaci√≥n y hue (ColorJitter)\n",
        "######################################################################################\n",
        "\n",
        "pipeline_color_jitter = A.Compose([\n",
        "    A.ColorJitter(brightness=0.2,\n",
        "                  contrast=0.2,\n",
        "                  saturation=0.2,\n",
        "                  hue=0.2,\n",
        "                  p=0.5),\n",
        "    A.Resize(640, 640)\n",
        "], bbox_params=A.BboxParams(format='yolo', label_fields=['labels']))\n",
        "\n",
        "######################################################################################\n",
        "# Lista de pipelines (se ha quitado el 'noise')\n",
        "######################################################################################\n",
        "\n",
        "pipelines = [\n",
        "    (\"flip\", pipeline_flip),\n",
        "    (\"rotate\", pipeline_rotate),\n",
        "    (\"shear\", pipeline_shear),\n",
        "    (\"bright\", pipeline_bright_contrast),\n",
        "    (\"blur\", pipeline_blur),\n",
        "    (\"color_jitter\", pipeline_color_jitter),\n",
        "    (\"noaug\", pipeline_no_aug)\n",
        "]\n",
        "\n",
        "def apply_pipeline(image_path, bboxes, labels, pipeline):\n",
        "    # Leemos la imagen en BGR\n",
        "    image = cv2.imread(image_path)\n",
        "    if image is None:\n",
        "        return None, None\n",
        "\n",
        "    # Aplicamos Albumentations directamente en BGR\n",
        "    augmented = pipeline(image=image, bboxes=bboxes, labels=labels)\n",
        "    aug_img = augmented[\"image\"]   # Esto es un array NumPy en BGR (uint8)\n",
        "    aug_bboxes = augmented[\"bboxes\"]\n",
        "    return aug_img, aug_bboxes\n",
        "\n",
        "######################################################################################\n",
        "# Directorios\n",
        "######################################################################################\n",
        "\n",
        "input_images_dir = \"/content/drive/MyDrive/fotos_pruebas\"\n",
        "input_labels_dir = \"/content/drive/MyDrive/fotos_pruebas\"\n",
        "output_images_dir = \"/content/dataset_aug4/images\"\n",
        "output_labels_dir = \"/content/dataset_aug4/labels\"\n",
        "\n",
        "os.makedirs(output_images_dir, exist_ok=True)\n",
        "os.makedirs(output_labels_dir, exist_ok=True)\n",
        "\n",
        "######################################################################################\n",
        "# Proceso de augmentaci√≥n\n",
        "######################################################################################\n",
        "\n",
        "for filename in os.listdir(input_images_dir):\n",
        "    if not filename.lower().endswith(('.jpg', '.jpeg', '.png')):\n",
        "        continue\n",
        "    img_path = os.path.join(input_images_dir, filename)\n",
        "    label_filename = os.path.splitext(filename)[0] + \".txt\"\n",
        "    label_path = os.path.join(input_labels_dir, label_filename)\n",
        "\n",
        "    bboxes, classes = read_yolo_labels(label_path)\n",
        "\n",
        "    # Si no hay anotaciones, copiamos la imagen original\n",
        "    if len(bboxes) == 0:\n",
        "        shutil.copy2(img_path, os.path.join(output_images_dir, filename))\n",
        "        open(os.path.join(output_labels_dir, label_filename), 'w').close()\n",
        "        continue\n",
        "\n",
        "    # Aplicamos cada pipeline\n",
        "    for suffix, pipeline in pipelines:\n",
        "        aug_img, aug_bboxes = apply_pipeline(img_path, bboxes, classes, pipeline)\n",
        "        if aug_img is None:\n",
        "            continue\n",
        "\n",
        "        new_img_name = os.path.splitext(filename)[0] + f\"_{suffix}\" + os.path.splitext(filename)[1]\n",
        "        new_label_name = os.path.splitext(filename)[0] + f\"_{suffix}\" + \".txt\"\n",
        "\n",
        "        # Guardamos la imagen aumentada\n",
        "        cv2.imwrite(os.path.join(output_images_dir, new_img_name), aug_img)\n",
        "\n",
        "        # Guardamos las anotaciones YOLO\n",
        "        with open(os.path.join(output_labels_dir, new_label_name), 'w') as f:\n",
        "            for cls, bbox in zip(classes, aug_bboxes):\n",
        "                f.write(f\"{cls} {bbox[0]:.6f} {bbox[1]:.6f} {bbox[2]:.6f} {bbox[3]:.6f}\\n\")\n",
        "\n",
        "    print(f\"Procesada {filename} con todos los pipelines.\")\n",
        "\n",
        "print(\"Data augmentation completo.\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 6.2 Data Augmentation parcial\n",
        "\n",
        "Se produce un n√∫mero random de transformaciones de data augmentation para cada imagen, por tanto, obtienes un n√∫mero random de imagenes positivas con transformaciones.\n",
        "\n",
        "(Siempre obtienes original)"
      ],
      "metadata": {
        "id": "w8OMaKk8XdXo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import cv2\n",
        "import albumentations as A\n",
        "import random\n",
        "import shutil\n",
        "\n",
        "# Funci√≥n para leer anotaciones en formato YOLO\n",
        "def read_yolo_labels(label_path):\n",
        "    \"\"\"\n",
        "    Lee un archivo de etiquetas YOLO y devuelve dos listas:\n",
        "    - bboxes: Lista de bounding boxes en formato [x_center, y_center, width, height] (normalizados).\n",
        "    - classes: Lista de clases (como string o n√∫mero) correspondiente a cada bbox.\n",
        "    \"\"\"\n",
        "    bboxes = []\n",
        "    classes = []\n",
        "    if os.path.exists(label_path):\n",
        "        with open(label_path, 'r') as f:\n",
        "            for line in f:\n",
        "                parts = line.strip().split()\n",
        "                if len(parts) == 5:\n",
        "                    classes.append(parts[0])\n",
        "                    bbox = list(map(float, parts[1:]))\n",
        "                    bboxes.append(bbox)\n",
        "    return bboxes, classes\n",
        "\n",
        "# Lista de transformaciones individuales disponibles\n",
        "# Se ha eliminado (\"noise\", A.GaussNoise(...))\n",
        "# Se ha a√±adido (\"color_jitter\", A.ColorJitter(...))\n",
        "augmentation_transforms = [\n",
        "    (\"flip\", A.HorizontalFlip(p=1.0)),\n",
        "    (\"rotate\", A.Rotate(limit=15, p=1.0)),      # Rota entre -15¬∞ y +15¬∞\n",
        "    (\"shear\", A.Affine(shear=15, p=1.0)),       # Aplica shear de 15¬∞\n",
        "    (\"bright\", A.RandomBrightnessContrast(brightness_limit=0.2, contrast_limit=0.2, p=1.0)),\n",
        "    (\"blur\", A.Blur(blur_limit=7, p=1.0)),\n",
        "    # NUEVA TRANSFORMACI√ìN PARA BRILLO/CONTRASTE/SATURACI√ìN/HUE\n",
        "    (\"color_jitter\", A.ColorJitter(\n",
        "        brightness=0.2,    # ¬±20% en brillo\n",
        "        contrast=0.2,      # ¬±20% en contraste\n",
        "        saturation=0.2,    # ¬±20% en saturaci√≥n\n",
        "        hue=0.2,           # ¬±20% en tono\n",
        "        p=1.0              # se aplica siempre; c√°mbialo a 0.5 si quieres probabilidad 50%\n",
        "    ))\n",
        "]\n",
        "\n",
        "def create_pipeline_for_transform(transform, target_size=(640, 640)):\n",
        "    \"\"\"\n",
        "    Crea una pipeline de Albumentations que aplica la transformaci√≥n dada,\n",
        "    luego redimensiona a target_size. NO se incluye ToTensorV2() para\n",
        "    evitar la conversi√≥n a tensores y conservar la imagen en NumPy.\n",
        "    \"\"\"\n",
        "    return A.Compose([\n",
        "        transform,\n",
        "        A.Resize(target_size[0], target_size[1], interpolation=cv2.INTER_LINEAR)\n",
        "    ], bbox_params=A.BboxParams(format='yolo', label_fields=['labels']))\n",
        "\n",
        "# Rutas de entrada\n",
        "input_images_dir = \"/content/drive/MyDrive/fotos_pruebas\"\n",
        "input_labels_dir = \"/content/drive/MyDrive/fotos_pruebas\"\n",
        "\n",
        "# Rutas de salida para im√°genes positivas (con anotaciones)\n",
        "output_images_dir = \"/content/dataset_aug100/positives/images\"\n",
        "output_labels_dir = \"/content/dataset_aug100/positives/labels\"\n",
        "os.makedirs(output_images_dir, exist_ok=True)\n",
        "os.makedirs(output_labels_dir, exist_ok=True)\n",
        "\n",
        "# Rutas de salida para im√°genes negativas (sin anotaciones)\n",
        "output_neg_images_dir = \"/content/dataset_aug100/negatives/images\"\n",
        "output_neg_labels_dir = \"/content/dataset_aug100/negatives/labels\"\n",
        "os.makedirs(output_neg_images_dir, exist_ok=True)\n",
        "os.makedirs(output_neg_labels_dir, exist_ok=True)\n",
        "\n",
        "# Iterar sobre cada imagen en el directorio de entrada\n",
        "for filename in os.listdir(input_images_dir):\n",
        "    if not filename.lower().endswith(('.jpg', '.jpeg', '.png')):\n",
        "        continue\n",
        "\n",
        "    img_path = os.path.join(input_images_dir, filename)\n",
        "    label_filename = os.path.splitext(filename)[0] + \".txt\"\n",
        "    label_path = os.path.join(input_labels_dir, label_filename)\n",
        "\n",
        "    # Leer las anotaciones (bounding boxes y clases)\n",
        "    bboxes, classes = read_yolo_labels(label_path)\n",
        "\n",
        "    # Si la imagen no tiene anotaciones, se considera \"negativa\"\n",
        "    if len(bboxes) == 0:\n",
        "        # Copiamos la imagen original a la carpeta de negativos\n",
        "        shutil.copy2(img_path, os.path.join(output_neg_images_dir, filename))\n",
        "        # Creamos un archivo TXT vac√≠o en la carpeta de negativos\n",
        "        open(os.path.join(output_neg_labels_dir, label_filename), 'w').close()\n",
        "        print(f\"{filename}: No tiene anotaciones. Copiada en negativos.\")\n",
        "        continue\n",
        "\n",
        "    # En caso de imagen \"positiva\", copiamos la original y sus anotaciones a la carpeta de positivos\n",
        "    shutil.copy2(img_path, os.path.join(output_images_dir, filename))\n",
        "    shutil.copy2(label_path, os.path.join(output_labels_dir, label_filename))\n",
        "\n",
        "    # Determinar de forma aleatoria cu√°ntas variantes se aplicar√°n (entre 1 y el total de transformaciones)\n",
        "    num_variants = random.randint(1, len(augmentation_transforms))\n",
        "    # Seleccionar aleatoriamente 'num_variants' transformaciones (sin combinarlas entre s√≠)\n",
        "    selected_transforms = random.sample(augmentation_transforms, num_variants)\n",
        "\n",
        "    # Para cada transformaci√≥n seleccionada, se aplica de forma individual\n",
        "    for suffix, transform in selected_transforms:\n",
        "        pipeline = create_pipeline_for_transform(transform, target_size=(640, 640))\n",
        "        try:\n",
        "            # 1) Leemos la imagen con OpenCV en BGR\n",
        "            image_bgr = cv2.imread(img_path)\n",
        "            if image_bgr is None:\n",
        "                print(f\"No se pudo leer {filename}, se omite.\")\n",
        "                continue\n",
        "\n",
        "            # 2) Convertimos a RGB para que Albumentations maneje bien las transformaciones de color\n",
        "            image_rgb = cv2.cvtColor(image_bgr, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "            # 3) Aplicamos el pipeline\n",
        "            result = pipeline(\n",
        "                image=image_rgb,\n",
        "                bboxes=bboxes,\n",
        "                labels=classes\n",
        "            )\n",
        "\n",
        "            # La imagen resultante en 'result[\"image\"]' sigue siendo un NumPy array (RGB, uint8)\n",
        "            aug_img = result[\"image\"]\n",
        "            aug_bboxes = result[\"bboxes\"]\n",
        "        except Exception as e:\n",
        "            print(f\"Error al aplicar {suffix} en {filename}: {e}\")\n",
        "            continue\n",
        "\n",
        "        if aug_img is None:\n",
        "            continue\n",
        "\n",
        "        # 4) Convertir de RGB a BGR para guardar de forma consistente\n",
        "        aug_img_bgr = cv2.cvtColor(aug_img, cv2.COLOR_RGB2BGR)\n",
        "\n",
        "        # 5) Generar un nuevo nombre de archivo para esta variante\n",
        "        new_img_name = os.path.splitext(filename)[0] + f\"_{suffix}\" + os.path.splitext(filename)[1]\n",
        "        new_label_name = os.path.splitext(filename)[0] + f\"_{suffix}\" + \".txt\"\n",
        "\n",
        "        # 6) Guardar la imagen aumentada (BGR) en disco\n",
        "        cv2.imwrite(os.path.join(output_images_dir, new_img_name), aug_img_bgr)\n",
        "\n",
        "        # 7) Guardar las anotaciones actualizadas en formato YOLO\n",
        "        with open(os.path.join(output_labels_dir, new_label_name), 'w') as f:\n",
        "            for cls, bbox in zip(classes, aug_bboxes):\n",
        "                f.write(f\"{cls} {bbox[0]:.6f} {bbox[1]:.6f} {bbox[2]:.6f} {bbox[3]:.6f}\\n\")\n",
        "\n",
        "        print(f\"{filename}: Variante '{suffix}' generada.\")\n",
        "\n",
        "    print(f\"Procesada {filename} con {num_variants} variantes aleatorias.\")\n",
        "\n",
        "print(\"Data augmentation completo: Se han generado las im√°genes aumentadas y sus archivos TXT correspondientes para im√°genes positivas, y se han copiado las im√°genes sin anotaciones en el set de negativos.\")\n"
      ],
      "metadata": {
        "id": "RgN2RBYny-zk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 6.3 Calcular n√∫meros archivos carpeta para hacer proporciones im√°genes positivas y negativas"
      ],
      "metadata": {
        "id": "7Ojty9tYfAEC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "# Rutas de las dos carpetas\n",
        "folder1 = \"/ruta/a/tu/carpeta1\"\n",
        "folder2 = \"/ruta/a/tu/carpeta2\"\n",
        "\n",
        "def count_files_in_folder(folder_path):\n",
        "    \"\"\"\n",
        "    Cuenta el n√∫mero de archivos (no directorios) en la carpeta dada.\n",
        "    \"\"\"\n",
        "    count = 0\n",
        "    for entry in os.listdir(folder_path):\n",
        "        full_path = os.path.join(folder_path, entry)\n",
        "        if os.path.isfile(full_path):\n",
        "            count += 1\n",
        "    return count\n",
        "\n",
        "# Contar archivos en cada carpeta\n",
        "count1 = count_files_in_folder(folder1)\n",
        "count2 = count_files_in_folder(folder2)\n",
        "\n",
        "# Mostrar resultados\n",
        "print(f\"Carpeta 1: {count1} archivos\")\n",
        "print(f\"Carpeta 2: {count2} archivos\")\n",
        "print(f\"Total de archivos en cada carpeta: Im√°genes {count1} + Labels: {count2}\")"
      ],
      "metadata": {
        "id": "V_fZcqhIfFxW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#6.4. Guardar resultados en Drive\n",
        "\n",
        "(en caso de que necesites guardar resultados)"
      ],
      "metadata": {
        "id": "y-QDsik89hl6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define la carpeta de destino en Google Drive\n",
        "dest_folder = \"/content/drive/MyDrive/fotos_pruebas/resultados3\"\n",
        "!mkdir -p \"{dest_folder}\"                                                           #El comando mkdir -p crea esa carpeta (y cualquier subcarpeta necesaria) si no existe.\n",
        "\n",
        "# Copia la carpeta de resultados (ajusta el nombre seg√∫n el que se haya generado)\n",
        "!cp -r /content/dataset_aug3 \"{dest_folder}/\"   #copiar los reultados del modelo en drive\n",
        "\n",
        "\n",
        "# Comprueba que se copiaron los archivos (opcional)\n",
        "!ls \"{dest_folder}\""
      ],
      "metadata": {
        "id": "hmwDN_fo9g1A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "amvcutJ7oQZQ"
      },
      "source": [
        "#7. WANDB\n",
        "\n",
        "Conectar Weights & Biases para poder seguir el proceso de aprendizaje\n",
        "\n",
        "Se guarda todo en la nube de la p√°gina web"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "MDl6vd7UlmWO",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 264
        },
        "outputId": "2995f7ee-a81c-47d1-8827-29dac7df0c0e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m This integration is tested and supported for ultralytics v8.0.238 and below.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m             Please report any issues to https://github.com/wandb/wandb/issues with the tag `yolov8`.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: No netrc file found, creating one.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33malberto22\u001b[0m (\u001b[33malberto22-university-centre-of-the-westfjords\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.19.8"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20250315_123053-8qwvej4c</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/alberto22-university-centre-of-the-westfjords/seals_2025%20/runs/8qwvej4c' target=\"_blank\">prime-sea-5</a></strong> to <a href='https://wandb.ai/alberto22-university-centre-of-the-westfjords/seals_2025%20' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/alberto22-university-centre-of-the-westfjords/seals_2025%20' target=\"_blank\">https://wandb.ai/alberto22-university-centre-of-the-westfjords/seals_2025%20</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/alberto22-university-centre-of-the-westfjords/seals_2025%20/runs/8qwvej4c' target=\"_blank\">https://wandb.ai/alberto22-university-centre-of-the-westfjords/seals_2025%20/runs/8qwvej4c</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/alberto22-university-centre-of-the-westfjords/seals_2025%20/runs/8qwvej4c?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>"
            ],
            "text/plain": [
              "<wandb.sdk.wandb_run.Run at 0x7a94b6c19150>"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "\n",
        "# 8. Autenticaci√≥n en Weights & Biases (W&B)\n",
        "import wandb\n",
        "from wandb.integration.ultralytics import add_wandb_callback\n",
        "\n",
        "# Initialize your Weights & Biases environment\n",
        "wandb.login(key=\"105f813f52ef215433a521087f025ed76bf34c23\")  # Te pedir√° ingresar tu API key o autenticarte desde el navegador.\n",
        "\n",
        "# Enable Weights & Biases logging\n",
        "yolo_settings_wandb=True\n",
        "\n",
        "# Disable Weights & Biases logging\n",
        "#yolo settings wandb=False\n",
        "\n",
        "\n",
        "#8.1 Initialize a Weight and Biases run:\n",
        "wandb.init(project= \"seals_2025 \", job_type= \"training\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 8. Mejorar la computaci√≥n de la GPU, somehow"
      ],
      "metadata": {
        "id": "enmAVKKViwO7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 5. Configurar PyTorch para GPU (opcional: optimizaci√≥n extra)\n",
        "import torch\n",
        "if torch.cuda.is_available():\n",
        "    torch.backends.cudnn.benchmark = True  # mejora la velocidad en convoluciones si el input es fijo"
      ],
      "metadata": {
        "id": "M0vwFCx-ix-L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-ej4pj-AoR9G"
      },
      "source": [
        "#9. Importar YOLO\n",
        "\n",
        "\n",
        "Impotamos el modelo de Yolo que vamos a usar\n",
        "\n",
        "Aseguramos que WANDb est√° conectado"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# 9. Ejecutar el entrenamiento de YOLOv8\n",
        "from ultralytics import YOLO\n",
        "\n",
        "# Carga el modelo (en este ejemplo, YOLOv8s)\n",
        "model = YOLO(\"yolov8s.pt\")\n",
        "\n",
        "#Add W&B callback for ultralytics:\n",
        "add_wandb_callback(model, True, True)\n",
        "\n"
      ],
      "metadata": {
        "id": "Rd7BSqGxvWup"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#10. Importar el data.yaml de drive\n",
        "\n",
        "una vez tenemos todo en Google colab,  para hacer bien los directorios"
      ],
      "metadata": {
        "id": "pO54PXOgc-8i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "################################IMPORTAR EL DAYA.YAML UNA VEZ TIENES LA ESTRUCTURA  ####################################################\n",
        "####################################################################################\n",
        "\n",
        "\n",
        "# Copiar el archivo data.yaml desde Drive a la ruta deseada en Colab\n",
        "!cp \"/content/drive/MyDrive/model_rar_640_tiles_labels/Fotos_elegidas/data.yaml\" \"/content/dataset_importado_bueno/Fotos_elegidas/data.yaml\"\n",
        "\n",
        "# Verificar que se copi√≥ correctamente\n",
        "!ls -l \"/content/dataset\""
      ],
      "metadata": {
        "id": "NFYpMaK4c-Nx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#11. **Train de model**\n",
        "\n",
        "El paso importante, entrenar al modelo.\n",
        "\n",
        "Anotar qu√© par√°metros usas para ver max perfomance y cambiar el data.yaml cuando se requiera"
      ],
      "metadata": {
        "id": "3B7VEZD7vbT1"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "38EAZnVwKPv3"
      },
      "outputs": [],
      "source": [
        "# Ejecuta el entrenamiento utilizando el archivo data.yaml en la carpeta extra√≠da.\n",
        "model.train(\n",
        "    project=\"seals_2025\",\n",
        "    name=\"focas_prueba_4_images\",\n",
        "    data=\"/content/dataset_importado_bueno/Fotos_elegidas/data.yaml\",  # Aseg√∫rate de que data.yaml use rutas correctas para Colab\n",
        "    epochs=100,                                                 # N√∫mero total de √©pocas (pasadas completas por el dataset de entrenamiento)\n",
        "    imgsz=640,                                                  # Tama√±o de la imagen (se reescala a 640x640)\n",
        "    batch=16,                                                   # N√∫mero de im√°genes por batch\n",
        "    lr0=0.001,        #probar 0.0005                            # Tasa de aprendizaje inicial. Un valor mayor hace que los pesos se actualicen m√°s r√°pido, pero puede inestabilizar el entrenamiento.\n",
        "    #momentun=0.937,                                            # Momentum para el optimizador (por ejemplo, en SGD)\n",
        "    optimizer=\"adamw\",       #otra opcion es = sgd              # Se usa AdamW (una variante de Adam que incorpora weight decay para evitar sobreajuste)\n",
        "    weight_decay=0.0005,                                        # Penalizaci√≥n sobre los pesos para prevenir sobreajuste. Si es muy alto, puede dificultar el aprendizaje; si es muy bajo, el modelo puede sobreajustarse.                                          # Se usa AdamW (una variante de Adam que incorpora weight decay para evitar sobreajuste)\n",
        "    #augment=False,                                             # Desactiva el data augmentation on the fly de YOLO##############  asi puedo hacer yo la data augmentation con las fotos con labels\n",
        "    #half=True,                                                 # Activa precisi√≥n mixta (FP16) para GPU\n",
        "    workers=16,                                                 # N√∫mero de workers para el DataLoader\n",
        "    #device='cuda' ,                                            # Fuerza el uso de GPU lo que acelera el entrenamiento\n",
        "     mosaic=1.0,                                                # Desactivar si las im√°genes son muy homog√©neas, es un data augmentation process\n",
        "    resume=True                                                 #PARA seguir entrenamiento donde lo dejaste\n",
        ")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rewm1mf0oMWk"
      },
      "source": [
        "#12 Gr√°ficas durante aprendizaje en Tensorboard\n",
        "\n",
        "para poder ver el aprendizaje, llamas a tensorboard"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T8YEnnujih17"
      },
      "outputs": [],
      "source": [
        "%load_ext tensorboard\n",
        "\n",
        "# Iniciar TensorBoard apuntando al directorio donde se guardan los logs\n",
        "%tensorboard --logdir /content/seals_2025/focas_prueba_4_images\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YM6eOoeLoKzl"
      },
      "source": [
        "# 13. Guardar resultados del modelo entrenado\n",
        "\n",
        "Tienes que fijarte donde se est√° guardando, normalmente algo como **runs**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iBSWPatloIgl"
      },
      "outputs": [],
      "source": [
        "# 10. Guardar los resultados del experimento\n",
        "\n",
        "# Define la carpeta de destino en Google Drive\n",
        "dest_folder = \"/content/drive/MyDrive/model_rar_640_tiles_labels/Fotos_elegidas/foquitas\"\n",
        "!mkdir -p \"{dest_folder}\"                                                           #El comando mkdir -p crea esa carpeta (y cualquier subcarpeta necesaria) si no existe.\n",
        "\n",
        "# Copia la carpeta de resultados (ajusta el nombre seg√∫n el que se haya generado)\n",
        "!cp -r /content/seals_2025/focas_prueba_4_images \"{dest_folder}/\"   #copiar los reultados del modelo en drive\n",
        "\n",
        "\n",
        "# Comprueba que se copiaron los archivos (opcional)\n",
        "!ls \"{dest_folder}\"                                                                 #verifica que los archivos se han copiado correctamente\n",
        "\n",
        "# Opcional: comprimir la carpeta de resultados para descargarla a tu PC\n",
        "!zip -r /content/foquitas.zip \"{dest_folder}/focas_prueba_4_images\"   #Aqu√≠ se comprime la carpeta que acabas de copiar en Drive (la subcarpeta focas_training_prueba1_640_24_02_25 dentro de foquitas) en un archivo ZIP llamado foquitas.zip que se guarda en /content (la carpeta principal del entorno de Colab).\n",
        "\n",
        "# Descargar el archivo ZIP a tu PC\n",
        "from google.colab import files\n",
        "files.download('/content/foquitas.zip')                                             #Este comando abre una ventana de descarga para que puedas bajar el archivo ZIP a tu ordenador."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#14  Validaci√≥n posterior\n",
        "\n",
        "Aqu√≠ puedes ajustar nivel de confianza e IOU para ver la validaci√≥n del modelo, a pesar d e que lo haga on the fly durante entrenamiento"
      ],
      "metadata": {
        "id": "hRW_Fv3HulOh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Cargar el modelo entrenado (ajusta la ruta seg√∫n corresponda)\n",
        "model = YOLO(\"runs/detect/train/weights/best.pt\")\n",
        "\n",
        "# Ejecutar validaci√≥n especificando el archivo de datos y los umbrales deseados\n",
        "metrics = model.val(data=\"data.yaml\", iou=0.3, conf=0.25)\n",
        "\n",
        "# Mostrar las m√©tricas obtenidas en la validaci√≥n\n",
        "print(\"M√©tricas de validaci√≥n:\", metrics)"
      ],
      "metadata": {
        "id": "KlXCo9lAunRQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#15. Inferencia\n",
        "\n",
        "Da como resultado, tanto las imagenes con bounding box, como el numero total de elementos por clase\n",
        "\n",
        "Recuerda conectar DRIVE Y ULTRALYTICS\n"
      ],
      "metadata": {
        "id": "oO-nxf_jO6L8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import json\n",
        "import csv\n",
        "import cv2\n",
        "import numpy as np\n",
        "from collections import defaultdict\n",
        "from ultralytics import YOLO\n",
        "\n",
        "# 1. Cargar el modelo\n",
        "model_path = \"/content/drive/MyDrive/model_rar_640_tiles_labels/Fotos_elegidas/foquitas/focas_prueba_4_images/weights/best.pt\"\n",
        "model = YOLO(model_path)\n",
        "\n",
        "# 2. Definir carpeta de entrada y salida\n",
        "input_folder = \"/content/drive/MyDrive/model_rar_640_tiles_labels/Fotos_elegidas/test/images\"\n",
        "output_folder = \"/content/inference_results_4\"\n",
        "os.makedirs(output_folder, exist_ok=True)\n",
        "\n",
        "# Dentro del output_folder, creamos dos subcarpetas: with_labels y no_labels\n",
        "with_labels_folder = os.path.join(output_folder, \"with_labels\")\n",
        "no_labels_folder = os.path.join(output_folder, \"no_labels\")\n",
        "os.makedirs(with_labels_folder, exist_ok=True)\n",
        "os.makedirs(no_labels_folder, exist_ok=True)\n",
        "\n",
        "# 3. Diccionarios para almacenar resultados\n",
        "results_dict = {}           # Por imagen: { \"imagen.jpg\": {\"seal\": 3, \"hole\": 2} }\n",
        "global_counts = defaultdict(int)  # Recuento total por clase\n",
        "\n",
        "# 4. Iterar sobre todas las im√°genes en la carpeta de entrada\n",
        "for filename in os.listdir(input_folder):\n",
        "    if filename.lower().endswith(('.jpg', '.jpeg', '.png')):\n",
        "        img_path = os.path.join(input_folder, filename)\n",
        "\n",
        "\n",
        "###########################################     Cambiar Par√°metros    ######################################################\n",
        "############################################################################################################################\n",
        "\n",
        "        # Realizar la inferencia (ajusta los par√°metros conf, iou, etc. si es necesario)\n",
        "        results = model.predict(source=img_path, imgsz=640, conf=0.25, iou=0.2, augment=False)\n",
        "\n",
        "############################################################################################################################\n",
        "############################################################################################################################\n",
        "\n",
        "        # Si hay resultados (normalmente 1 por imagen si se pasa una sola imagen al modelo)\n",
        "        if len(results) > 0:\n",
        "            result = results[0]\n",
        "\n",
        "            # 5. Dibujar las detecciones en la imagen\n",
        "            rendered_img = result.plot()   # Devuelve una imagen (array numpy en RGB)\n",
        "            # Convertir de RGB a BGR para guardar con cv2\n",
        "            rendered_bgr = cv2.cvtColor(rendered_img, cv2.COLOR_RGB2BGR)\n",
        "\n",
        "            # Determinar si hay al menos una detecci√≥n\n",
        "            if result.boxes is not None and len(result.boxes) > 0:\n",
        "                # S√≠ hay detecciones\n",
        "                out_img_folder = with_labels_folder\n",
        "            else:\n",
        "                # No hay detecciones\n",
        "                out_img_folder = no_labels_folder\n",
        "\n",
        "            # Guardar la imagen con bounding boxes en la carpeta correspondiente\n",
        "            out_img_path = os.path.join(out_img_folder, filename)\n",
        "            cv2.imwrite(out_img_path, rendered_bgr)\n",
        "\n",
        "            # 6. Contar las detecciones por clase\n",
        "            if result.boxes is not None and len(result.boxes) > 0:\n",
        "                cls_tensor = result.boxes.cls\n",
        "                cls_indices = cls_tensor.cpu().numpy().tolist()\n",
        "                class_names = [model.names[int(idx)] for idx in cls_indices]\n",
        "            else:\n",
        "                class_names = []\n",
        "\n",
        "            count_dict = {}\n",
        "            for cls_name in class_names:\n",
        "                count_dict[cls_name] = count_dict.get(cls_name, 0) + 1\n",
        "\n",
        "            # Guardar en results_dict\n",
        "            results_dict[filename] = count_dict\n",
        "\n",
        "            # Acumular en global_counts\n",
        "            for cls_name, cnt in count_dict.items():\n",
        "                global_counts[cls_name] += cnt\n",
        "\n",
        "            print(f\"Inferencia realizada: {filename}\")\n",
        "        else:\n",
        "            print(f\"No se obtuvieron resultados para: {filename}\")\n",
        "\n",
        "# 7. Guardar los resultados en CSV y JSON\n",
        "\n",
        "# CSV: tendremos filas de la forma [filename, class, count] para cada imagen,\n",
        "# luego una fila \"TOTAL\" por clase\n",
        "csv_file = os.path.join(output_folder, \"inference_counts.csv\")\n",
        "with open(csv_file, \"w\", newline=\"\") as f:\n",
        "    writer = csv.writer(f)\n",
        "    writer.writerow([\"filename\", \"class\", \"count\"])\n",
        "\n",
        "    # Escribir los datos por imagen\n",
        "    for fname, counts in results_dict.items():\n",
        "        if len(counts) == 0:\n",
        "            # Imagen sin detecciones\n",
        "            writer.writerow([fname, \"no_detections\", 0])\n",
        "        else:\n",
        "            for cls, cnt in counts.items():\n",
        "                writer.writerow([fname, cls, cnt])\n",
        "\n",
        "    # Agregar filas de TOTales (una por clase)\n",
        "    for cls, cnt in global_counts.items():\n",
        "        writer.writerow([\"TOTAL\", cls, cnt])\n",
        "\n",
        "# JSON: contendr√° un objeto con \"por_imagen\" y \"totales\"\n",
        "json_data = {\n",
        "    \"por_imagen\": results_dict,\n",
        "    \"totales\": dict(global_counts)\n",
        "}\n",
        "\n",
        "json_file = os.path.join(output_folder, \"inference_counts.json\")\n",
        "with open(json_file, \"w\") as f:\n",
        "    json.dump(json_data, f, indent=4)\n",
        "\n",
        "print(\"Inferencia completada. Resultados guardados en:\")\n",
        "print(f\"- {with_labels_folder} -> im√°genes con detecciones\")\n",
        "print(f\"- {no_labels_folder} -> im√°genes sin detecciones\")\n",
        "print(f\"- {csv_file}\")\n",
        "print(f\"- {json_file}\")\n"
      ],
      "metadata": {
        "id": "aGxgvjok-6bz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#16. Guardar resultados de la Inferencia"
      ],
      "metadata": {
        "id": "vw6MxkKWty9a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define la carpeta de destino en Google Drive\n",
        "dest_folder = \"/content/drive/MyDrive/model_rar_640_tiles_labels/Fotos_elegidas/resultadosfinales_2_cambiandoiou\"\n",
        "!mkdir -p \"{dest_folder}\"                                                           #El comando mkdir -p crea esa carpeta (y cualquier subcarpeta necesaria) si no existe.\n",
        "\n",
        "# Copia la carpeta de resultados (ajusta el nombre seg√∫n el que se haya generado)\n",
        "!cp -r /content/inference_results_4 \"{dest_folder}/\"   #copiar los reultados del modelo en drive\n",
        "\n",
        "\n",
        "# Comprueba que se copiaron los archivos (opcional)\n",
        "!ls \"{dest_folder}\"                                                                 #verifica que los archivos se han copiado correctamente\n",
        "\n",
        "# Opcional: comprimir la carpeta de resultados para descargarla a tu PC\n",
        "!zip -r /content/inferencia_2.zip \"{dest_folder}/inference_results_4\"   #Aqu√≠ se comprime la carpeta que acabas de copiar en Drive (la subcarpeta focas_training_prueba1_640_24_02_25 dentro de foquitas) en un archivo ZIP llamado foquitas.zip que se guarda en /content (la carpeta principal del entorno de Colab).\n",
        "\n",
        "# Descargar el archivo ZIP a tu PC\n",
        "from google.colab import files\n",
        "files.download('/content/inferencia_2.zip')                                             #Este comando abre una ventana de descarga para que puedas bajar el archivo ZIP a tu ordenador."
      ],
      "metadata": {
        "id": "xCsbd1d78o2D"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}