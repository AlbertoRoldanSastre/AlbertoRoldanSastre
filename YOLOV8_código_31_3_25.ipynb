{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AlbertoRoldanSastre/AlbertoRoldanSastre/blob/main/YOLOV8_c%C3%B3digo_31_3_25.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# C√≥digo para el entrenamiento del modelo YOLOv8 ( n, s, m, l, x)"
      ],
      "metadata": {
        "id": "QeczupJOY2_d"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G60lb_jPlMfO"
      },
      "source": [
        "# 0. Memoria ram y capacidad de memoria\n",
        "\n",
        "Vamos a comprobar que memoria ram y capacidad estamos usando en Colab"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "JUJ72Ly0lMVO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9511bbbc-223e-411f-a96f-97d72239840d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Your runtime has 89.6 gigabytes of available RAM\n",
            "\n",
            "You are using a high-RAM runtime!\n"
          ]
        }
      ],
      "source": [
        "from psutil import virtual_memory\n",
        "ram_gb = virtual_memory().total / 1e9\n",
        "print('Your runtime has {:.1f} gigabytes of available RAM\\n'.format(ram_gb))\n",
        "\n",
        "if ram_gb < 20:\n",
        "  print('Not using a high-RAM runtime')\n",
        "else:\n",
        "  print('You are using a high-RAM runtime!')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "brkDhF4FkqVw"
      },
      "source": [
        "# 1. Chequear si tengo GPU y cual"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "x3jfFCX2hAbC"
      },
      "outputs": [],
      "source": [
        "gpu_info = !nvidia-smi\n",
        "gpu_info = '\\n'.join(gpu_info)\n",
        "if gpu_info.find('failed') >= 0:\n",
        "  print('Not connected to a GPU')\n",
        "else:\n",
        "  print(gpu_info)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JzV1b5ejlXNJ"
      },
      "source": [
        "# 2. Importar librer√≠as\n",
        "\n",
        "Importamos librer√≠as importantes para el proceso"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#0. En Colab, primero instala los paquetes y monta tu Drive:  Instalar las librer√≠as necesarias\n",
        "!pip install ultralytics wandb  # Esto instalar√° ultralytics y wandb (torch y torchvision generalmente ya vienen instalados en Colab)\n",
        "\n",
        "import ultralytics\n",
        "ultralytics.checks()"
      ],
      "metadata": {
        "id": "vBN6CVOMXMzJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e9f799e9-d54f-4725-956d-819be116dacc"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ultralytics 8.3.99 üöÄ Python-3.11.11 torch-2.6.0+cu124 CUDA:0 (NVIDIA A100-SXM4-40GB, 40507MiB)\n",
            "Setup complete ‚úÖ (12 CPUs, 83.5 GB RAM, 41.2/235.7 GB disk)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3. Conectar con Google Drive"
      ],
      "metadata": {
        "id": "QJMCCI_LYfjh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Montar Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')           #cambiar la ruta de drive de donde lo extraes"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z1vapCDQYiOL",
        "outputId": "74cdcc98-9e88-4db4-dce1-06ca4eaf7102"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#4. Importar archivos"
      ],
      "metadata": {
        "id": "99bBCzLUbUPp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "# Rutas de las dos carpetas\n",
        "folder1 = \"/content/drive/MyDrive/AWS.v39i.seals+holes/ready/va/images\"\n",
        "folder2 = \"/content/drive/MyDrive/AWS.v39i.seals+holes/ready/valid/labels\"\n",
        "\n",
        "def count_files_in_folder(folder_path):\n",
        "    \"\"\"\n",
        "    Cuenta el n√∫mero de archivos (no directorios) en la carpeta dada.\n",
        "    \"\"\"\n",
        "    count = 0\n",
        "    for entry in os.listdir(folder_path):\n",
        "        full_path = os.path.join(folder_path, entry)\n",
        "        if os.path.isfile(full_path):\n",
        "            count += 1\n",
        "    return count\n",
        "\n",
        "# Contar archivos en cada carpeta\n",
        "count1 = count_files_in_folder(folder1)\n",
        "count2 = count_files_in_folder(folder2)\n",
        "\n",
        "# Mostrar resultados\n",
        "print(f\"Carpeta 1: {count1} archivos\")\n",
        "print(f\"Carpeta 2: {count2} archivos\")\n",
        "print(f\"Total de archivos en cada carpeta: Im√°genes {count1} + Labels: {count2}\")"
      ],
      "metadata": {
        "id": "V_fZcqhIfFxW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c32c32ea-2d56-416e-d136-f26b7d436215"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Carpeta 1: 0 archivos\n",
            "Carpeta 2: 0 archivos\n",
            "Total de archivos en cada carpeta: Im√°genes 0 + Labels: 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4.1  Importar carpetas desde Google Drive si no est√°n en Rar"
      ],
      "metadata": {
        "id": "3wWN1qGYaYPp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# 2. Definir las carpetas en Google Drive que deseas importar\n",
        "# Por ejemplo, si tienes dos carpetas: una para im√°genes y otra para etiquetas\n",
        "folders_to_copy = [\n",
        "    \"/content/drive/MyDrive/AWS.v39i.seals+holes/ready\"  # Carpeta con im√°genes\n",
        "   # \"/content/drive/MyDrive/Tmodel_rar_640_tiles_labels/fotos_elegidas/labels\"   # Carpeta con archivos txt\n",
        "]\n",
        "\n",
        "# 3. Definir un directorio de destino en Colab donde copiar√°s estas carpetas\n",
        "destination_base = \"/content/dataset_importado\"\n",
        "import os\n",
        "os.makedirs(destination_base, exist_ok=True)\n",
        "\n",
        "# 4. Copiar cada carpeta desde Drive al directorio local\n",
        "for folder in folders_to_copy:\n",
        "    folder_name = os.path.basename(folder)\n",
        "    dest = os.path.join(destination_base, folder_name)\n",
        "    # El comando cp -r copia recursivamente la carpeta\n",
        "    !cp -r \"{folder}\" \"{dest}\"\n",
        "\n",
        "# 5. Verificar que se copiaron las carpetas\n",
        "!ls -l \"{destination_base}\""
      ],
      "metadata": {
        "id": "lGgKCEFWbTLI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#4.2.  Descomprimir archivos rar de Drive a Google collab directamente si est√°n en rar"
      ],
      "metadata": {
        "id": "MriKZEjdXmHn"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VyZmo2KIlfU1"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "# 2. Instalar unrar para poder descomprimir archivos RAR\n",
        "!apt-get update\n",
        "!apt-get install -y unrar\n",
        "\n",
        "\n",
        "\n",
        "# 4. Definir las rutas de los archivos RAR en Drive\n",
        "# Ajusta estas rutas seg√∫n d√≥nde est√©n ubicados en tu Drive\n",
        "images_train_rar = \"/content/drive/MyDrive/model_rar_640_tiles_labels/train/images.rar\"\n",
        "labels_train_rar = \"/content/drive/MyDrive/model_rar_640_tiles_labels/train/labels.rar\"\n",
        "images_validation_rar = \"/content/drive/MyDrive/model_rar_640_tiles_labels/valid/images.rar\"\n",
        "labels_validation_rar = \"/content/drive/MyDrive/model_rar_640_tiles_labels//valid/labels.rar\"\n",
        "\n",
        "# 5. Definir las carpetas de destino en Colab para cada uno\n",
        "# Estas carpetas mantendr√°n la estructura de YOLO (por ejemplo, \"images\" y \"labels\")\n",
        "dest_train_images = \"/content/dataset/train\"    # he dejado image sy labels en el mismo directorio a ver si as√≠ se apa√±a el no detectar labels\n",
        "dest_train_labels = \"/content/dataset/train\"\n",
        "dest_val_images = \"/content/dataset/val\"\n",
        "dest_val_labels = \"/content/dataset/val\"\n",
        "\n",
        "import os\n",
        "os.makedirs(dest_train_images, exist_ok=True)\n",
        "os.makedirs(dest_train_labels, exist_ok=True)\n",
        "os.makedirs(dest_val_images, exist_ok=True)\n",
        "os.makedirs(dest_val_labels, exist_ok=True)\n",
        "\n",
        "# 6. Descomprimir cada archivo RAR en su carpeta correspondiente\n",
        "!unrar x \"{images_train_rar}\" \"{dest_train_images}/\"\n",
        "!unrar x \"{labels_train_rar}\" \"{dest_train_labels}/\"\n",
        "!unrar x \"{images_validation_rar}\" \"{dest_val_images}/\"\n",
        "!unrar x \"{labels_validation_rar}\" \"{dest_val_labels}/\"\n",
        "\n",
        "# Opcional: listar el contenido para confirmar que se descomprimi√≥ correctamente\n",
        "!ls /content/dataset/train/       # he dejado image sy labels en el mismo directorio a ver si as√≠ se apa√±a el no detectar labels\n",
        "!ls /content/dataset/train/\n",
        "!ls /content/dataset/val/\n",
        "!ls /content/dataset/val/\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "amvcutJ7oQZQ"
      },
      "source": [
        "#7. WANDB\n",
        "\n",
        "Conectar Weights & Biases para poder seguir el proceso de aprendizaje\n",
        "\n",
        "Se guarda todo en la nube de la p√°gina web"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MDl6vd7UlmWO"
      },
      "outputs": [],
      "source": [
        "\n",
        "# 8. Autenticaci√≥n en Weights & Biases (W&B)\n",
        "import wandb\n",
        "from wandb.integration.ultralytics import add_wandb_callback\n",
        "\n",
        "# Initialize your Weights & Biases environment\n",
        "wandb.login(key=\"105f813f52ef215433a521087f025ed76bf34c23\")  # Te pedir√° ingresar tu API key o autenticarte desde el navegador.\n",
        "\n",
        "# Enable Weights & Biases logging\n",
        "yolo_settings_wandb=True\n",
        "\n",
        "# Disable Weights & Biases logging\n",
        "#yolo settings wandb=False\n",
        "\n",
        "\n",
        "#8.1 Initialize a Weight and Biases run:\n",
        "wandb.init(project= \"seals_2025 \", job_type= \"training\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 8. Mejorar la computaci√≥n de la GPU, somehow"
      ],
      "metadata": {
        "id": "enmAVKKViwO7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 5. Configurar PyTorch para GPU (opcional: optimizaci√≥n extra)\n",
        "import torch\n",
        "if torch.cuda.is_available():\n",
        "    torch.backends.cudnn.benchmark = True  # mejora la velocidad en convoluciones si el input es fijo"
      ],
      "metadata": {
        "id": "M0vwFCx-ix-L"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#9. Importar el DATASET Y data.yaml de drive\n",
        "\n",
        "una vez tenemos todo en Google colab,  para hacer bien los directorios"
      ],
      "metadata": {
        "id": "pO54PXOgc-8i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "################################IMPORTAR EL dataset entero a colab UNA VEZ TIENES LA ESTRUCTURA  ####################################################\n",
        "####################################################################################\n",
        "\n",
        "\n",
        "# Copiar el archivo data.yaml desde Drive a la ruta deseada en Colab\n",
        "!cp -r \"/content/drive/MyDrive/AWS.v39i.seals_plus_holes/ready/train/images\" \"/content/dataset/train/\"\n",
        "\n",
        "# Verificar que se copi√≥ correctamente\n",
        "!ls -l \"/content/dataset\""
      ],
      "metadata": {
        "id": "7g1Bqv_25eye"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "# Rutas de las dos carpetas\n",
        "folder1 = \"/content/dataset/train/images\"\n",
        "folder2 = \"/content/dataset/train/labels\"\n",
        "\n",
        "def count_files_in_folder(folder_path):\n",
        "    \"\"\"\n",
        "    Cuenta el n√∫mero de archivos (no directorios) en la carpeta dada.\n",
        "    \"\"\"\n",
        "    count = 0\n",
        "    for entry in os.listdir(folder_path):\n",
        "        full_path = os.path.join(folder_path, entry)\n",
        "        if os.path.isfile(full_path):\n",
        "            count += 1\n",
        "    return count\n",
        "\n",
        "# Contar archivos en cada carpeta\n",
        "count1 = count_files_in_folder(folder1)\n",
        "count2 = count_files_in_folder(folder2)\n",
        "\n",
        "# Mostrar resultados\n",
        "print(f\"Carpeta 1: {count1} archivos\")\n",
        "print(f\"Carpeta 2: {count2} archivos\")\n",
        "print(f\"Total de archivos en cada carpeta: Im√°genes {count1} + Labels: {count2}\")"
      ],
      "metadata": {
        "id": "Hmr8aEhLlYfP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "para cambiar questionable seal a seal"
      ],
      "metadata": {
        "id": "VfWlqnMTFueB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "def reemplazar_clase_en_txts(ruta_labels, clase_origen=1, clase_destino=2):\n",
        "    \"\"\"\n",
        "    Reemplaza la clase_origen por clase_destino al inicio de cada l√≠nea en archivos YOLO .txt.\n",
        "\n",
        "    Args:\n",
        "        ruta_labels (str): Carpeta que contiene archivos .txt en formato YOLO.\n",
        "        clase_origen (int): ID de la clase que quieres reemplazar (por defecto: 1).\n",
        "        clase_destino (int): ID de la clase que quieres usar en su lugar (por defecto: 2).\n",
        "    \"\"\"\n",
        "    txt_files = [f for f in os.listdir(ruta_labels) if f.endswith(\".txt\")]\n",
        "\n",
        "    for file in txt_files:\n",
        "        file_path = os.path.join(ruta_labels, file)\n",
        "\n",
        "        with open(file_path, \"r\") as f:\n",
        "            lineas = f.readlines()\n",
        "\n",
        "        nuevas_lineas = []\n",
        "        for linea in lineas:\n",
        "            partes = linea.strip().split()\n",
        "            if partes and partes[0] == str(clase_origen):\n",
        "                partes[0] = str(clase_destino)\n",
        "            nuevas_lineas.append(\" \".join(partes) + \"\\n\")\n",
        "\n",
        "        with open(file_path, \"w\") as f:\n",
        "            f.writelines(nuevas_lineas)\n",
        "\n",
        "        print(f\"‚úÖ Archivo procesado: {file}\")\n",
        "\n",
        "# üß™ Ejemplo de uso:\n",
        "carpeta_labels = \"/content/dataset/valid/labels\"  # Reemplaza por la ruta correcta\n",
        "reemplazar_clase_en_txts(carpeta_labels)\n"
      ],
      "metadata": {
        "id": "MKG5p0p6FwaC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-ej4pj-AoR9G"
      },
      "source": [
        "#10. Importar YOLO\n",
        "\n",
        "\n",
        "Impotamos el modelo de Yolo que vamos a usar\n",
        "\n",
        "Aseguramos que WANDb est√° conectado"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# 9. Ejecutar el entrenamiento de YOLOv8\n",
        "from ultralytics import YOLO\n",
        "\n",
        "# Carga el modelo (en este ejemplo, YOLOv8s)\n",
        "model = YOLO(\"yolov8s.pt\")\n",
        "\n",
        "#Add W&B callback for ultralytics:\n",
        "#add_wandb_callback(model, True, True)\n",
        "\n"
      ],
      "metadata": {
        "id": "Rd7BSqGxvWup"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#11. **Train de model**\n",
        "\n",
        "El paso importante, entrenar al modelo.\n",
        "\n",
        "Anotar qu√© par√°metros usas para ver max perfomance y cambiar el data.yaml cuando se requiera"
      ],
      "metadata": {
        "id": "3B7VEZD7vbT1"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "38EAZnVwKPv3"
      },
      "outputs": [],
      "source": [
        "# Ejecuta el entrenamiento utilizando el archivo data.yaml en la carpeta extra√≠da.\n",
        "model.train(\n",
        "    project=\"seals_2025\",\n",
        "    name=\"focas_prueba_snow_yolov8s_without_ques\",\n",
        "    data=\"/content/dataset/data.yaml\",  # Aseg√∫rate de que data.yaml use rutas correctas para Colab\n",
        "    epochs=15,                                                  # N√∫mero total de √©pocas (pasadas completas por el dataset de entrenamiento)\n",
        "    imgsz=640,                                                  # Tama√±o de la imagen (se reescala a 640x640)\n",
        "    batch=16,                                                   # N√∫mero de im√°genes por batch\n",
        "    lr0=0.001,        #probar 0.0005                            # Tasa de aprendizaje inicial. Un valor mayor hace que los pesos se actualicen m√°s r√°pido, pero puede inestabilizar el entrenamiento.\n",
        "    momentum=0.937,                                             # Momentum para el optimizador (por ejemplo, en SGD)\n",
        "    warmup_momentum=0.8,                                        # La fase de \"warmup\" es un per√≠odo inicial en el que la tasa de aprendizaje y otros par√°metros (como el momentum) se ajustan gradualmente.    Esto ayuda a estabilizar el entrenamiento y a evitar que el modelo se desv√≠e demasiado al principio.\n",
        "    optimizer=\"adamw\",       #otra opcion es = sgd              # Se usa AdamW (una variante de Adam que incorpora weight decay para evitar sobreajuste)\n",
        "    weight_decay=0.0005,                                        # Penalizaci√≥n sobre los pesos para prevenir sobreajuste. Si es muy alto, puede dificultar el aprendizaje; si es muy bajo, el modelo puede sobreajustarse.                                          # Se usa AdamW (una variante de Adam que incorpora weight decay para evitar sobreajuste)\n",
        "    #augment=False,                                             # Desactiva el data augmentation on the fly de YOLO##############  asi puedo hacer yo la data augmentation con las fotos con labels\n",
        "    half=True,                                                  # Activa precisi√≥n mixta (FP16) para GPU\n",
        "    workers=8,                                                  # N√∫mero de workers para el DataLoader\n",
        "    device='cuda' ,                                            # Fuerza el uso de GPU lo que acelera el entrenamiento\n",
        "    #mosaic=0,                                                  # Desactivar si las im√°genes son muy homog√©neas, es un data augmentation process\n",
        "    #resume=True,                                               #PARA seguir entrenamiento donde lo dejaste\n",
        "    #validate=False                                              # para no hacer validaci√≥n a la vez que entrena\n",
        "    patience=15                                                 # si el modelo no aprende m√°s en la epoch 15, se para. si tras \"X\" epochs la m√©trica val/best_map_50 no mejora, se detiene el entrenamiento autom√°ticamente.\n",
        ")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rewm1mf0oMWk"
      },
      "source": [
        "#12 Gr√°ficas durante aprendizaje en Tensorboard\n",
        "\n",
        "para poder ver el aprendizaje, llamas a tensorboard"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T8YEnnujih17"
      },
      "outputs": [],
      "source": [
        "%load_ext tensorboard\n",
        "\n",
        "# Iniciar TensorBoard apuntando al directorio donde se guardan los logs\n",
        "%tensorboard --logdir /content/seals_2025/focas_prueba_snow\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YM6eOoeLoKzl"
      },
      "source": [
        "# 13. Guardar resultados del modelo entrenado\n",
        "\n",
        "Tienes que fijarte donde se est√° guardando, normalmente algo como **runs**"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import locale\n",
        "def getpreferredencoding(do_setlocale = True):\n",
        "    return \"UTF-8\"\n",
        "locale.getpreferredencoding = getpreferredencoding"
      ],
      "metadata": {
        "id": "XtCJZxp_Ef6F"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "iBSWPatloIgl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a79ed4ca-3a95-40d4-dd7c-f1734a11d381"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "focas_prueba_snow_yolov8s_without_ques\n"
          ]
        }
      ],
      "source": [
        "# 10. Guardar los resultados del experimento\n",
        "\n",
        "# Define la carpeta de destino en Google Drive\n",
        "dest_folder = \"/content/drive/MyDrive/AWS.v39i.seals_plus_holes/resultados_yolov8s_sinquestionableseal\"\n",
        "!mkdir -p \"{dest_folder}\"  # El comando mkdir -p crea esa carpeta (y cualquier subcarpeta necesaria) si no existe.\n",
        "\n",
        "# Copia la carpeta de resultados (ajusta el nombre seg√∫n el que se haya generado)\n",
        "!cp -r /content/seals_2025/focas_prueba_snow_yolov8s_without_ques \"{dest_folder}/\"  # Copiar los resultados del modelo en drive\n",
        "\n",
        "# Comprueba que se copiaron los archivos (opcional)\n",
        "!ls \"{dest_folder}\"\n",
        "\n",
        "# Opcional: comprimir la carpeta de resultados para descargarla a tu PC\n",
        "#zip_output_path = \"/content/negative_images.zip\"  # Ruta temporal para almacenar el archivo ZIP en el entorno de Colab\n",
        "\n",
        "# Corrige la ruta de compresi√≥n para comprimir la carpeta images_negatives correctamente\n",
        "#!zip -r \"{zip_output_path}\" \"{dest_folder}/images_negatives\"  # Aqu√≠ se comprime la carpeta que acabas de copiar en Drive (images_negatives) en un archivo ZIP.\n",
        "\n",
        "# Descargar el archivo ZIP a tu PC\n",
        "#from google.colab import files\n",
        "#files.download(zip_output_path)  # Descargar el archivo comprimido                                       #Este comando abre una ventana de descarga para que puedas bajar el archivo ZIP a tu ordenador."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#14  Validaci√≥n posterior\n",
        "\n",
        "Aqu√≠ puedes ajustar nivel de confianza e IOU para ver la validaci√≥n del modelo, a pesar d e que lo haga on the fly durante entrenamiento"
      ],
      "metadata": {
        "id": "hRW_Fv3HulOh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Cargar el modelo entrenado (ajusta la ruta seg√∫n corresponda)\n",
        "model = YOLO(\"/content/seals_2025/focas_prueba_snow/weights/best.pt\")\n",
        "\n",
        "# Ejecutar validaci√≥n especificando el archivo de datos y los umbrales deseados\n",
        "metrics = model.val(data=\"/content/dataset/data.yaml\", iou=0.35, conf=0.35)\n",
        "\n",
        "# Mostrar las m√©tricas obtenidas en la validaci√≥n\n",
        "print(\"M√©tricas de validaci√≥n:\", metrics)"
      ],
      "metadata": {
        "id": "KlXCo9lAunRQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9a9c797c-4e03-4b79-c52c-aee8bf600449",
        "id": "VHI4ybuPzGax"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "focas_prueba_snow_yolov8m2\n"
          ]
        }
      ],
      "source": [
        "# 10. Guardar los resultados del experimento\n",
        "\n",
        "# Define la carpeta de destino en Google Drive\n",
        "dest_folder = \"/content/drive/MyDrive/dataset_selectedplus_snow23_3.yolov8/resultados_yolov8m_without_quest\"\n",
        "!mkdir -p \"{dest_folder}\"                                                           #El comando mkdir -p crea esa carpeta (y cualquier subcarpeta necesaria) si no existe.\n",
        "\n",
        "# Copia la carpeta de resultados (ajusta el nombre seg√∫n el que se haya generado)\n",
        "!cp -r /content/seals_2025/focas_prueba_snow_yolov8m2 \"{dest_folder}/\"   #copiar los reultados del modelo en drive\n",
        "\n",
        "\n",
        "# Comprueba que se copiaron los archivos (opcional)\n",
        "!ls \"{dest_folder}\"                                                                 #verifica que los archivos se han copiado correctamente\n",
        "\n",
        "# Opcional: comprimir la carpeta de resultados para descargarla a tu PC\n",
        "#!zip -r /content/seals_2025/focas_prueba_snow.zip \"{dest_folder}/focas_prueba_snow\"   #Aqu√≠ se comprime la carpeta que acabas de copiar en Drive (la subcarpeta focas_training_prueba1_640_24_02_25 dentro de foquitas) en un archivo ZIP llamado foquitas.zip que se guarda en /content (la carpeta principal del entorno de Colab).\n",
        "\n",
        "# Descargar el archivo ZIP a tu PC\n",
        "#from google.colab import files\n",
        "#files.download('/content/seals_2025/focas_prueba_snow.zip')                                             #Este comando abre una ventana de descarga para que puedas bajar el archivo ZIP a tu ordenador."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#15. Inferencia\n",
        "\n",
        "Da como resultado, tanto las imagenes con bounding box, como el numero total de elementos por clase\n",
        "\n",
        "Recuerda conectar DRIVE Y ULTRALYTICS\n"
      ],
      "metadata": {
        "id": "oO-nxf_jO6L8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import json\n",
        "import csv\n",
        "import cv2\n",
        "import numpy as np\n",
        "from collections import defaultdict\n",
        "from ultralytics import YOLO\n",
        "\n",
        "# 1. Cargar el modelo\n",
        "model_path = \"/content/drive/MyDrive/model_rar_640_tiles_labels/Fotos_elegidas/foquitas/focas_prueba_4_images/weights/best.pt\"\n",
        "model = YOLO(model_path)\n",
        "\n",
        "# 2. Definir carpeta de entrada y salida\n",
        "input_folder = \"/content/drive/MyDrive/model_rar_640_tiles_labels/Fotos_elegidas/test/images\"\n",
        "output_folder = \"/content/inference_results_4\"\n",
        "os.makedirs(output_folder, exist_ok=True)\n",
        "\n",
        "# Dentro del output_folder, creamos dos subcarpetas: with_labels y no_labels\n",
        "with_labels_folder = os.path.join(output_folder, \"with_labels\")\n",
        "no_labels_folder = os.path.join(output_folder, \"no_labels\")\n",
        "os.makedirs(with_labels_folder, exist_ok=True)\n",
        "os.makedirs(no_labels_folder, exist_ok=True)\n",
        "\n",
        "# 3. Diccionarios para almacenar resultados\n",
        "results_dict = {}           # Por imagen: { \"imagen.jpg\": {\"seal\": 3, \"hole\": 2} }\n",
        "global_counts = defaultdict(int)  # Recuento total por clase\n",
        "\n",
        "# 4. Iterar sobre todas las im√°genes en la carpeta de entrada\n",
        "for filename in os.listdir(input_folder):\n",
        "    if filename.lower().endswith(('.jpg', '.jpeg', '.png')):\n",
        "        img_path = os.path.join(input_folder, filename)\n",
        "\n",
        "\n",
        "###########################################     Cambiar Par√°metros    ######################################################\n",
        "############################################################################################################################\n",
        "\n",
        "        # Realizar la inferencia (ajusta los par√°metros conf, iou, etc. si es necesario)\n",
        "        results = model.predict(source=img_path, imgsz=640, conf=0.25, iou=0.2, augment=False)\n",
        "\n",
        "############################################################################################################################\n",
        "############################################################################################################################\n",
        "\n",
        "        # Si hay resultados (normalmente 1 por imagen si se pasa una sola imagen al modelo)\n",
        "        if len(results) > 0:\n",
        "            result = results[0]\n",
        "\n",
        "            # 5. Dibujar las detecciones en la imagen\n",
        "            rendered_img = result.plot()   # Devuelve una imagen (array numpy en RGB)\n",
        "            # Convertir de RGB a BGR para guardar con cv2\n",
        "            rendered_bgr = cv2.cvtColor(rendered_img, cv2.COLOR_RGB2BGR)\n",
        "\n",
        "            # Determinar si hay al menos una detecci√≥n\n",
        "            if result.boxes is not None and len(result.boxes) > 0:\n",
        "                # S√≠ hay detecciones\n",
        "                out_img_folder = with_labels_folder\n",
        "            else:\n",
        "                # No hay detecciones\n",
        "                out_img_folder = no_labels_folder\n",
        "\n",
        "            # Guardar la imagen con bounding boxes en la carpeta correspondiente\n",
        "            out_img_path = os.path.join(out_img_folder, filename)\n",
        "            cv2.imwrite(out_img_path, rendered_bgr)\n",
        "\n",
        "            # 6. Contar las detecciones por clase\n",
        "            if result.boxes is not None and len(result.boxes) > 0:\n",
        "                cls_tensor = result.boxes.cls\n",
        "                cls_indices = cls_tensor.cpu().numpy().tolist()\n",
        "                class_names = [model.names[int(idx)] for idx in cls_indices]\n",
        "            else:\n",
        "                class_names = []\n",
        "\n",
        "            count_dict = {}\n",
        "            for cls_name in class_names:\n",
        "                count_dict[cls_name] = count_dict.get(cls_name, 0) + 1\n",
        "\n",
        "            # Guardar en results_dict\n",
        "            results_dict[filename] = count_dict\n",
        "\n",
        "            # Acumular en global_counts\n",
        "            for cls_name, cnt in count_dict.items():\n",
        "                global_counts[cls_name] += cnt\n",
        "\n",
        "            print(f\"Inferencia realizada: {filename}\")\n",
        "        else:\n",
        "            print(f\"No se obtuvieron resultados para: {filename}\")\n",
        "\n",
        "# 7. Guardar los resultados en CSV y JSON\n",
        "\n",
        "# CSV: tendremos filas de la forma [filename, class, count] para cada imagen,\n",
        "# luego una fila \"TOTAL\" por clase\n",
        "csv_file = os.path.join(output_folder, \"inference_counts.csv\")\n",
        "with open(csv_file, \"w\", newline=\"\") as f:\n",
        "    writer = csv.writer(f)\n",
        "    writer.writerow([\"filename\", \"class\", \"count\"])\n",
        "\n",
        "    # Escribir los datos por imagen\n",
        "    for fname, counts in results_dict.items():\n",
        "        if len(counts) == 0:\n",
        "            # Imagen sin detecciones\n",
        "            writer.writerow([fname, \"no_detections\", 0])\n",
        "        else:\n",
        "            for cls, cnt in counts.items():\n",
        "                writer.writerow([fname, cls, cnt])\n",
        "\n",
        "    # Agregar filas de TOTales (una por clase)\n",
        "    for cls, cnt in global_counts.items():\n",
        "        writer.writerow([\"TOTAL\", cls, cnt])\n",
        "\n",
        "# JSON: contendr√° un objeto con \"por_imagen\" y \"totales\"\n",
        "json_data = {\n",
        "    \"por_imagen\": results_dict,\n",
        "    \"totales\": dict(global_counts)\n",
        "}\n",
        "\n",
        "json_file = os.path.join(output_folder, \"inference_counts.json\")\n",
        "with open(json_file, \"w\") as f:\n",
        "    json.dump(json_data, f, indent=4)\n",
        "\n",
        "print(\"Inferencia completada. Resultados guardados en:\")\n",
        "print(f\"- {with_labels_folder} -> im√°genes con detecciones\")\n",
        "print(f\"- {no_labels_folder} -> im√°genes sin detecciones\")\n",
        "print(f\"- {csv_file}\")\n",
        "print(f\"- {json_file}\")\n"
      ],
      "metadata": {
        "id": "aGxgvjok-6bz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#16. Guardar resultados de la Inferencia"
      ],
      "metadata": {
        "id": "vw6MxkKWty9a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define la carpeta de destino en Google Drive\n",
        "dest_folder = \"/content/drive/MyDrive/model_rar_640_tiles_labels/Fotos_elegidas/resultadosfinales_2_cambiandoiou\"\n",
        "!mkdir -p \"{dest_folder}\"                                                           #El comando mkdir -p crea esa carpeta (y cualquier subcarpeta necesaria) si no existe.\n",
        "\n",
        "# Copia la carpeta de resultados (ajusta el nombre seg√∫n el que se haya generado)\n",
        "!cp -r /content/inference_results_4 \"{dest_folder}/\"   #copiar los reultados del modelo en drive\n",
        "\n",
        "\n",
        "# Comprueba que se copiaron los archivos (opcional)\n",
        "!ls \"{dest_folder}\"                                                                 #verifica que los archivos se han copiado correctamente\n",
        "\n",
        "# Opcional: comprimir la carpeta de resultados para descargarla a tu PC\n",
        "!zip -r /content/inferencia_2.zip \"{dest_folder}/inference_results_4\"   #Aqu√≠ se comprime la carpeta que acabas de copiar en Drive (la subcarpeta focas_training_prueba1_640_24_02_25 dentro de foquitas) en un archivo ZIP llamado foquitas.zip que se guarda en /content (la carpeta principal del entorno de Colab).\n",
        "\n",
        "# Descargar el archivo ZIP a tu PC\n",
        "from google.colab import files\n",
        "files.download('/content/inferencia_2.zip')                                             #Este comando abre una ventana de descarga para que puedas bajar el archivo ZIP a tu ordenador."
      ],
      "metadata": {
        "id": "xCsbd1d78o2D"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}