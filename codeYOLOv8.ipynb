{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AlbertoRoldanSastre/AlbertoRoldanSastre/blob/main/codeYOLOv8.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G60lb_jPlMfO"
      },
      "source": [
        "Memoria ram y capacidad de memoria"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JUJ72Ly0lMVO",
        "outputId": "3cf2fc8c-c5b3-4332-abbc-9cb301d7a4e6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Your runtime has 54.8 gigabytes of available RAM\n",
            "\n",
            "You are using a high-RAM runtime!\n"
          ]
        }
      ],
      "source": [
        "from psutil import virtual_memory\n",
        "ram_gb = virtual_memory().total / 1e9\n",
        "print('Your runtime has {:.1f} gigabytes of available RAM\\n'.format(ram_gb))\n",
        "\n",
        "if ram_gb < 20:\n",
        "  print('Not using a high-RAM runtime')\n",
        "else:\n",
        "  print('You are using a high-RAM runtime!')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "brkDhF4FkqVw"
      },
      "source": [
        "Chequear si tengo gpu y cual"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "x3jfFCX2hAbC",
        "outputId": "51010350-d78f-4593-bc79-eb0ff035e81a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/bin/bash: line 1: nvidia-smi: command not found\n"
          ]
        }
      ],
      "source": [
        "gpu_info = !nvidia-smi\n",
        "gpu_info = '\\n'.join(gpu_info)\n",
        "if gpu_info.find('failed') >= 0:\n",
        "  print('Not connected to a GPU')\n",
        "else:\n",
        "  print(gpu_info)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JzV1b5ejlXNJ"
      },
      "source": [
        "Importar imágenes y librerías\n",
        "\n",
        "estas en rar, hay que descomprimir y eso"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VyZmo2KIlfU1"
      },
      "outputs": [],
      "source": [
        "#0. En Colab, primero instala los paquetes y monta tu Drive:  Instalar las librerías necesarias\n",
        "!pip install ultralytics wandb  # Esto instalará ultralytics y wandb (torch y torchvision generalmente ya vienen instalados en Colab)\n",
        "\n",
        "import ultralytics\n",
        "ultralytics.checks()\n",
        "\n",
        "# 1. Montar Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')           #cambiar la ruta de drive de donde lo extraes\n",
        "\n",
        "# 2. Instalar unrar para poder descomprimir archivos RAR\n",
        "!apt-get update\n",
        "!apt-get install -y unrar\n",
        "\n",
        "# 3. Descomprimir el archivo RAR desde Google Drive\n",
        "# Ajusta la ruta del archivo RAR a la ubicación correcta en tu Drive.\n",
        "# Este comando extrae el contenido del archivo a la carpeta /content/dataset/\n",
        "#!unrar x \"/content/drive/MyDrive/YourDatasetFolder/your_dataset.rar\" /content/dataset/\n",
        "\n",
        "\n",
        "#OPCION A:\n",
        "\n",
        "# 4. Definir las rutas de los archivos RAR en Drive\n",
        "# Ajusta estas rutas según dónde estén ubicados en tu Drive\n",
        "images_train_rar = \"/content/drive/MyDrive/model_rar_640_tiles_labels/train/images.rar\"\n",
        "labels_train_rar = \"/content/drive/MyDrive/model_rar_640_tiles_labels/train/labels.rar\"\n",
        "images_validation_rar = \"/content/drive/MyDrive/model_rar_640_tiles_labels/valid/images.rar\"\n",
        "labels_validation_rar = \"/content/drive/MyDrive/model_rar_640_tiles_labels//valid/labels.rar\"\n",
        "\n",
        "# 5. Definir las carpetas de destino en Colab para cada uno\n",
        "# Estas carpetas mantendrán la estructura de YOLO (por ejemplo, \"images\" y \"labels\")\n",
        "dest_train_images = \"/content/dataset/train\"    # he dejado image sy labels en el mismo directorio a ver si así se apaña el no detectar labels\n",
        "dest_train_labels = \"/content/dataset/train\"\n",
        "dest_val_images = \"/content/dataset/val\"\n",
        "dest_val_labels = \"/content/dataset/val\"\n",
        "\n",
        "import os\n",
        "os.makedirs(dest_train_images, exist_ok=True)\n",
        "os.makedirs(dest_train_labels, exist_ok=True)\n",
        "os.makedirs(dest_val_images, exist_ok=True)\n",
        "os.makedirs(dest_val_labels, exist_ok=True)\n",
        "\n",
        "# 6. Descomprimir cada archivo RAR en su carpeta correspondiente\n",
        "!unrar x \"{images_train_rar}\" \"{dest_train_images}/\"\n",
        "!unrar x \"{labels_train_rar}\" \"{dest_train_labels}/\"\n",
        "!unrar x \"{images_validation_rar}\" \"{dest_val_images}/\"\n",
        "!unrar x \"{labels_validation_rar}\" \"{dest_val_labels}/\"\n",
        "\n",
        "# Opcional: listar el contenido para confirmar que se descomprimió correctamente\n",
        "!ls /content/dataset/train/       # he dejado image sy labels en el mismo directorio a ver si así se apaña el no detectar labels\n",
        "!ls /content/dataset/train/\n",
        "!ls /content/dataset/val/\n",
        "!ls /content/dataset/val/\n",
        "\n",
        "\n",
        "#OPCION B:\n",
        "\n",
        "# 4. Iterar sobre cada archivo RAR en la carpeta de origen y descomprimirlo\n",
        "#for file in os.listdir(source_folder):\n",
        "#    if file.lower().endswith(\".rar\"):\n",
        "#        rar_path = os.path.join(source_folder, file)\n",
        "#        print(\"Descomprimiendo:\", rar_path)\n",
        "#        # Ejecuta el comando unrar para extraer el contenido al destination_folder\n",
        "#        !unrar x \"{rar_path}\" \"{destination_folder}/\"\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "OVERSAMPLING: (solo con las fotos con etiquetas)\n",
        " (aumentar el número de fotos positivas solo para poder tener más que enseñar)\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "gj4aQDS9NtJ3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import shutil\n",
        "\n",
        "# Rutas de las carpetas originales\n",
        "orig_images_dir = \"/content/dataset/train/images\"\n",
        "orig_labels_dir = \"/content/dataset/train/labels\"\n",
        "\n",
        "# Carpeta de destino para el dataset balanceado\n",
        "balanced_dir = \"/content/balanced_train\"\n",
        "balanced_images_dir = os.path.join(balanced_dir, \"images\")\n",
        "balanced_labels_dir = os.path.join(balanced_dir, \"labels\")\n",
        "\n",
        "os.makedirs(balanced_images_dir, exist_ok=True)\n",
        "os.makedirs(balanced_labels_dir, exist_ok=True)\n",
        "\n",
        "################################################################\n",
        "################################################################\n",
        "# Factor de duplicación para imágenes positivas\n",
        "dup_factor = 3                                                      ########cuantas veces las quiero multiplicar\n",
        "\n",
        "#################################################################\n",
        "\n",
        "# Recorremos todas las imágenes del dataset original\n",
        "for filename in os.listdir(orig_images_dir):\n",
        "    if not filename.lower().endswith(('.jpg','.jpeg','.png')):\n",
        "        continue\n",
        "    # Ruta de la imagen y de la etiqueta correspondiente\n",
        "    orig_img_path = os.path.join(orig_images_dir, filename)\n",
        "    label_filename = os.path.splitext(filename)[0] + \".txt\"\n",
        "    orig_label_path = os.path.join(orig_labels_dir, label_filename)\n",
        "\n",
        "    # Determinar si la imagen es positiva (tiene anotaciones) o negativa\n",
        "    is_positive = False\n",
        "    if os.path.exists(orig_label_path):\n",
        "        with open(orig_label_path, 'r') as f:\n",
        "            content = f.read().strip()\n",
        "        if content:  # Si hay algo, es positiva\n",
        "            is_positive = True\n",
        "\n",
        "    # Copiar la imagen y el archivo de etiqueta al nuevo directorio\n",
        "    # Si es positiva, duplicamos según el factor\n",
        "    copies = dup_factor if is_positive else 1\n",
        "    for i in range(copies):\n",
        "        # Para evitar sobreescritura, agregamos un sufijo en el nombre de la imagen duplicada\n",
        "        new_filename = os.path.splitext(filename)[0]\n",
        "        if copies > 1:\n",
        "            new_filename += f\"_{i+1}\"\n",
        "        new_filename += os.path.splitext(filename)[1]\n",
        "        new_img_path = os.path.join(balanced_images_dir, new_filename)\n",
        "        shutil.copy2(orig_img_path, new_img_path)\n",
        "\n",
        "        # También copiamos la etiqueta (si existe), ajustando el nombre\n",
        "        if os.path.exists(orig_label_path):\n",
        "            new_label_filename = os.path.splitext(label_filename)[0]\n",
        "            if copies > 1:\n",
        "                new_label_filename += f\"_{i+1}\"\n",
        "            new_label_filename += \".txt\"\n",
        "            new_label_path = os.path.join(balanced_labels_dir, new_label_filename)\n",
        "            shutil.copy2(orig_label_path, new_label_path)\n",
        "\n",
        "print(\"Dataset balanceado creado en:\", balanced_dir)\n"
      ],
      "metadata": {
        "id": "OQo8bjMaN1y8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**DATA AUGMENTATION**\n",
        "solo aplicado a las fotos previamente procesadas (con etiquetas)\n",
        "\n",
        "produce una imagen por cada transformacion mas la original mas labels que contienen la info de las clases"
      ],
      "metadata": {
        "id": "9ieORmaSQAmh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import cv2\n",
        "import albumentations as A\n",
        "from albumentations.pytorch import ToTensorV2\n",
        "import shutil\n",
        "\n",
        "# Función para leer anotaciones en formato YOLO\n",
        "def read_yolo_labels(label_path):\n",
        "    \"\"\"\n",
        "    Lee un archivo de etiquetas YOLO y devuelve dos listas:\n",
        "    - bboxes: Lista de bounding boxes en formato [x_center, y_center, width, height] (valores normalizados)\n",
        "    - classes: Lista de clases (como string o número) correspondiente a cada bbox.\n",
        "    \"\"\"\n",
        "    bboxes = []\n",
        "    classes = []\n",
        "    if os.path.exists(label_path):\n",
        "        with open(label_path, 'r') as f:\n",
        "            for line in f:\n",
        "                parts = line.strip().split()\n",
        "                if len(parts) == 5:\n",
        "                    classes.append(parts[0])\n",
        "                    bbox = list(map(float, parts[1:]))\n",
        "                    bboxes.append(bbox)\n",
        "    return bboxes, classes\n",
        "\n",
        "# Definir pipelines individuales para cada transformación (se aplican siempre, p=1.0)\n",
        "pipeline_flip = A.Compose([\n",
        "    A.HorizontalFlip(p=1.0),\n",
        "    A.Resize(640, 640),\n",
        "    ToTensorV2()\n",
        "], bbox_params=A.BboxParams(format='yolo', label_fields=['labels']))\n",
        "\n",
        "pipeline_rotate = A.Compose([\n",
        "    A.Rotate(limit=15, p=1.0),  # Rota entre -15° y +15°\n",
        "    A.Resize(640, 640),\n",
        "    ToTensorV2()\n",
        "], bbox_params=A.BboxParams(format='yolo', label_fields=['labels']))\n",
        "\n",
        "pipeline_shear = A.Compose([\n",
        "    A.Affine(shear=15, p=1.0),\n",
        "    A.Resize(640, 640),\n",
        "    ToTensorV2()\n",
        "], bbox_params=A.BboxParams(format='yolo', label_fields=['labels']))\n",
        "\n",
        "pipeline_bright_contrast = A.Compose([\n",
        "    A.RandomBrightnessContrast(brightness_limit=0.2, contrast_limit=0.2, p=1.0),\n",
        "    A.Resize(640, 640),\n",
        "    ToTensorV2()\n",
        "], bbox_params=A.BboxParams(format='yolo', label_fields=['labels']))\n",
        "\n",
        "pipeline_blur = A.Compose([\n",
        "    A.Blur(blur_limit=7, p=1.0),\n",
        "    A.Resize(640, 640),\n",
        "    ToTensorV2()\n",
        "], bbox_params=A.BboxParams(format='yolo', label_fields=['labels']))\n",
        "\n",
        "pipeline_noise = A.Compose([\n",
        "    A.GaussianNoise(var_limit=(10.0, 50.0), p=1.0),\n",
        "    A.Resize(640, 640),\n",
        "    ToTensorV2()\n",
        "], bbox_params=A.BboxParams(format='yolo', label_fields=['labels']))\n",
        "\n",
        "# Pipeline sin augmentation (solo resize) para referencia\n",
        "pipeline_no_aug = A.Compose([\n",
        "    A.Resize(640, 640),\n",
        "    ToTensorV2()\n",
        "], bbox_params=A.BboxParams(format='yolo', label_fields=['labels']))\n",
        "\n",
        "# Lista de pipelines con un sufijo para el nombre de archivo\n",
        "pipelines = [\n",
        "    (\"flip\", pipeline_flip),\n",
        "    (\"rotate\", pipeline_rotate),\n",
        "    (\"shear\", pipeline_shear),\n",
        "    (\"bright\", pipeline_bright_contrast),\n",
        "    (\"blur\", pipeline_blur),\n",
        "    (\"noise\", pipeline_noise),\n",
        "    (\"noaug\", pipeline_no_aug)\n",
        "]\n",
        "\n",
        "def apply_pipeline(image_path, bboxes, labels, pipeline):\n",
        "    \"\"\"\n",
        "    Aplica un pipeline de augmentación a una imagen y sus bounding boxes.\n",
        "    Retorna la imagen aumentada (tensor convertido a numpy) y las nuevas bounding boxes.\n",
        "    \"\"\"\n",
        "    image = cv2.imread(image_path)\n",
        "    if image is None:\n",
        "        return None, None\n",
        "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "    augmented = pipeline(image=image, bboxes=bboxes, labels=labels)\n",
        "    aug_img = augmented[\"image\"]  # Tensor (C, H, W) con valores en [0,1]\n",
        "    # Convertir a numpy (H, W, C), escalar a 0-255 y volver a BGR para guardar con cv2\n",
        "    aug_img_np = aug_img.permute(1, 2, 0).cpu().numpy() * 255\n",
        "    aug_img_np = aug_img_np.astype('uint8')\n",
        "    aug_img_np = cv2.cvtColor(aug_img_np, cv2.COLOR_RGB2BGR)\n",
        "    return aug_img_np, augmented[\"bboxes\"]\n",
        "\n",
        "# Directorios de entrada (dataset original)\n",
        "input_images_dir = \"/content/dataset/train/images\"\n",
        "input_labels_dir = \"/content/dataset/train/labels\"\n",
        "\n",
        "# Directorios de salida para el dataset aumentado\n",
        "output_images_dir = \"/content/dataset_aug/train/images\"\n",
        "output_labels_dir = \"/content/dataset_aug/train/labels\"\n",
        "\n",
        "os.makedirs(output_images_dir, exist_ok=True)\n",
        "os.makedirs(output_labels_dir, exist_ok=True)\n",
        "\n",
        "# Iterar sobre cada imagen en el dataset de entrenamiento\n",
        "for filename in os.listdir(input_images_dir):\n",
        "    if not filename.lower().endswith(('.jpg', '.jpeg', '.png')):\n",
        "        continue\n",
        "    img_path = os.path.join(input_images_dir, filename)\n",
        "    label_filename = os.path.splitext(filename)[0] + \".txt\"\n",
        "    label_path = os.path.join(input_labels_dir, label_filename)\n",
        "\n",
        "    # Leer anotaciones\n",
        "    bboxes, classes = read_yolo_labels(label_path)\n",
        "\n",
        "    # Si no hay anotaciones, decide si deseas aplicar augmentación o solo copiar la imagen\n",
        "    if len(bboxes) == 0:\n",
        "        # Por ejemplo, copia la imagen original sin cambios\n",
        "        shutil.copy2(img_path, os.path.join(output_images_dir, filename))\n",
        "        # Crea un archivo de etiquetas vacío en el output\n",
        "        open(os.path.join(output_labels_dir, label_filename), 'w').close()\n",
        "        continue\n",
        "\n",
        "    # Aplicar cada pipeline a la imagen positiva\n",
        "    for suffix, pipeline in pipelines:\n",
        "        aug_img, aug_bboxes = apply_pipeline(img_path, bboxes, classes, pipeline)\n",
        "        if aug_img is None:\n",
        "            continue\n",
        "        # Genera un nuevo nombre de archivo que incluya el sufijo de la transformación\n",
        "        new_img_name = os.path.splitext(filename)[0] + f\"_{suffix}\" + os.path.splitext(filename)[1]\n",
        "        new_label_name = os.path.splitext(filename)[0] + f\"_{suffix}\" + \".txt\"\n",
        "        # Guardar la imagen aumentada\n",
        "        cv2.imwrite(os.path.join(output_images_dir, new_img_name), aug_img)\n",
        "        # Guardar las anotaciones aumentadas en el mismo formato YOLO\n",
        "        with open(os.path.join(output_labels_dir, new_label_name), 'w') as f:\n",
        "            for cls, bbox in zip(classes, aug_bboxes):\n",
        "                f.write(f\"{cls} {bbox[0]:.6f} {bbox[1]:.6f} {bbox[2]:.6f} {bbox[3]:.6f}\\n\")\n",
        "    print(f\"Procesada {filename} con todos los pipelines.\")\n",
        "\n",
        "print(\"Data augmentation completo: se han generado múltiples imágenes por cada imagen original.\")\n"
      ],
      "metadata": {
        "id": "WcF9TYkiV6Tz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "amvcutJ7oQZQ"
      },
      "source": [
        "WANDB"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MDl6vd7UlmWO"
      },
      "outputs": [],
      "source": [
        "\n",
        "# 8. Autenticación en Weights & Biases (W&B)\n",
        "import wandb\n",
        "from wandb.integration.ultralytics import add_wandb_callback\n",
        "\n",
        "# Initialize your Weights & Biases environment\n",
        "wandb.login(key=\"105f813f52ef215433a521087f025ed76bf34c23\")  # Te pedirá ingresar tu API key o autenticarte desde el navegador.\n",
        "\n",
        "# Enable Weights & Biases logging\n",
        "yolo_settings_wandb=True\n",
        "\n",
        "# Disable Weights & Biases logging\n",
        "#yolo settings wandb=False\n",
        "\n",
        "\n",
        "#8.1 Initialize a Weight and Biases run:\n",
        "wandb.init(project= \"seals_2025 \", job_type= \"training\")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "mejorar gpu computación"
      ],
      "metadata": {
        "id": "enmAVKKViwO7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 5. Configurar PyTorch para GPU (opcional: optimización extra)\n",
        "import torch\n",
        "if torch.cuda.is_available():\n",
        "    torch.backends.cudnn.benchmark = True  # mejora la velocidad en convoluciones si el input es fijo"
      ],
      "metadata": {
        "id": "M0vwFCx-ix-L"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-ej4pj-AoR9G"
      },
      "source": [
        "YOLO"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "38EAZnVwKPv3"
      },
      "outputs": [],
      "source": [
        "\n",
        "# 9. Ejecutar el entrenamiento de YOLOv8\n",
        "from ultralytics import YOLO\n",
        "\n",
        "# Carga el modelo (en este ejemplo, YOLOv8s)\n",
        "model = YOLO(\"yolov8s.pt\")\n",
        "\n",
        "#Add W&B callback for ultralytics:\n",
        "add_wandb_callback(model, True, True)\n",
        "\n",
        "# Ejecuta el entrenamiento utilizando el archivo data.yaml en la carpeta extraída.\n",
        "model.train(\n",
        "    project=\"seals_2025\",\n",
        "    name=\"focas_training_prueba1_640_24_02_25\",\n",
        "    data=\"/content/drive/MyDrive/model_rar_640_tiles_labels/data.yaml\",  # Asegúrate de que data.yaml use rutas correctas para Colab\n",
        "    epochs=5,\n",
        "    imgsz=640,\n",
        "    batch=16,\n",
        "    lr0=0.001,\n",
        "    optimizer=\"adamw\",\n",
        "    augment=False,      # Desactiva el data augmentation on the fly de YOLO##############  asi puedo hacer yo la data augmentation con las fotos con labels\n",
        "    half=True,           # Activa precisión mixta (FP16) para GPU\n",
        "    workers=16,          # Número de workers para el DataLoader\n",
        "    device='cuda'        # Fuerza el uso de GPU\n",
        ")\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rewm1mf0oMWk"
      },
      "source": [
        "Gráficas durante aprendizaje en Tensorboard"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T8YEnnujih17"
      },
      "outputs": [],
      "source": [
        "%load_ext tensorboard\n",
        "\n",
        "# Iniciar TensorBoard apuntando al directorio donde se guardan los logs\n",
        "%tensorboard --logdir /content/seals_2025/focas_training_prueba1_640_24_02_25\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YM6eOoeLoKzl"
      },
      "source": [
        "Guardar resultados"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iBSWPatloIgl"
      },
      "outputs": [],
      "source": [
        "# 10. Guardar los resultados del experimento\n",
        "\n",
        "# Define la carpeta de destino en Google Drive\n",
        "dest_folder = \"/content/drive/MyDrive/model_rar_640_tiles_labels/foquitas\"\n",
        "!mkdir -p \"{dest_folder}\"                                                           #El comando mkdir -p crea esa carpeta (y cualquier subcarpeta necesaria) si no existe.\n",
        "\n",
        "# Copia la carpeta de resultados (ajusta el nombre según el que se haya generado)\n",
        "!cp -r /content/seals_2025/focas_training_prueba1_640_24_02_25 \"{dest_folder}/\"   #copiar los reultados del modelo en drive\n",
        "\n",
        "\n",
        "# Comprueba que se copiaron los archivos (opcional)\n",
        "!ls \"{dest_folder}\"                                                                 #verifica que los archivos se han copiado correctamente\n",
        "\n",
        "# Opcional: comprimir la carpeta de resultados para descargarla a tu PC\n",
        "!zip -r /content/foquitas.zip \"{dest_folder}/focas_training_prueba1_640_24_02_25\"   #Aquí se comprime la carpeta que acabas de copiar en Drive (la subcarpeta focas_training_prueba1_640_24_02_25 dentro de foquitas) en un archivo ZIP llamado foquitas.zip que se guarda en /content (la carpeta principal del entorno de Colab).\n",
        "\n",
        "# Descargar el archivo ZIP a tu PC\n",
        "from google.colab import files\n",
        "files.download('/content/foquitas.zip')                                             #Este comando abre una ventana de descarga para que puedas bajar el archivo ZIP a tu ordenador."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "machine_shape": "hm",
      "provenance": [],
      "gpuType": "A100",
      "authorship_tag": "ABX9TyOHwy35l1yI557Z9CwxIx6F",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}