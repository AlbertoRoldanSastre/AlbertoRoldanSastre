{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CEweGJLjUdG6"
      },
      "source": [
        "# PASOS PARA LA DESCARGA DEL DATASET Y PREPARACIÓN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-1AfO_ouUdG8"
      },
      "source": [
        "Crear el ambiente virtual para que incluso si muevo archivos funcione:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xfS9NMgDUdG8"
      },
      "source": [
        "En esta hoja voy a detallar todos los procesos que me han funcionado para poder descargar el dataset, transformar  y dejar todo listo para correr el modelo:"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 0) Conectar con Drive"
      ],
      "metadata": {
        "id": "764Unx2vUmdV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Montar Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "BmTKQDTNUn51"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_SLlfx5aUdG8"
      },
      "source": [
        "# 1) Descargar el dataset con las anotaciones desde Roboflow\n",
        "\n",
        "cuando descargo versión, lo hago produciendo versión con auto-oriented, nada más, no tiling no resize (esto la haré luego yo)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "85fdJ0GdUdG9"
      },
      "outputs": [],
      "source": [
        "#if not installed, you need to install roboflow in terminal  : pip install roboflow\n",
        "\n",
        "from roboflow import Roboflow\n",
        "\n",
        "rf = Roboflow(api_key=\"9eeIO2PsJSso62o9\")\n",
        "\n",
        "project = rf.workspace(\"seals-cqpqc\").project(\"aws-qgxmp\")          # nombre del workspace y del projecto\n",
        "dataset = project.version(10).download(\"YOLOV8\")                     # \"6\" ES la versión que descargué , adaptala a la tuya. YOLOV8 es el formato\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NIW5GQInUdG9"
      },
      "source": [
        "#2) Transformar las anotaciones a formato YOLO (es decir, bounding box)\n",
        "\n",
        "esto es porque al decargar anotaciones, yo tengo poligonos y bounding boxes, quiero que todas sean bounding boxed que es lo que el modelo acepta\n",
        "\n",
        "Haces carpeta a carpeta (train- validation-test)\n",
        "\n",
        "otra opción es: Use a framework that accepts mixed annotations without modification (e.g., PyTorch with COCO JSON format)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FXlOePKBUdG9"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "def polygon_to_bbox(coords):\n",
        "    \"\"\"\n",
        "    Convierte una lista de coordenadas de un polígono (x1, y1, x2, y2, ..., xN, yN)\n",
        "    a una bounding box en formato YOLO: (x_center, y_center, width, height),\n",
        "    asumiendo que las coordenadas están normalizadas [0,1].\n",
        "    \"\"\"\n",
        "    xs = coords[0::2]  # extrae todos los valores de x\n",
        "    ys = coords[1::2]  # extrae todos los valores de y\n",
        "\n",
        "    x_min = min(xs)\n",
        "    x_max = max(xs)\n",
        "    y_min = min(ys)\n",
        "    y_max = max(ys)\n",
        "\n",
        "    x_center = (x_min + x_max) / 2.0\n",
        "    y_center = (y_min + y_max) / 2.0\n",
        "    width = x_max - x_min\n",
        "    height = y_max - y_min\n",
        "\n",
        "    return x_center, y_center, width, height\n",
        "\n",
        "def process_label_file(src_file, dst_file):\n",
        "    \"\"\"\n",
        "    Lee un archivo de anotaciones en formato YOLO (líneas con la clase seguida de coordenadas).\n",
        "    Si la línea contiene 4 números (bounding box), la deja igual.\n",
        "    Si contiene más de 4 (asumiendo un polígono), lo convierte a bounding box.\n",
        "    Escribe el resultado en un nuevo archivo.\n",
        "    \"\"\"\n",
        "    with open(src_file, 'r') as f_in:\n",
        "        lines = f_in.readlines()\n",
        "\n",
        "    new_lines = []\n",
        "    for line in lines:\n",
        "        line = line.strip()\n",
        "        if not line:\n",
        "            continue\n",
        "        parts = line.split()\n",
        "        cls = parts[0]  # la clase (por ejemplo, \"0\", \"1\", \"2\", etc.)       ##clases indicadas en data.yaml\n",
        "        coords = list(map(float, parts[1:]))\n",
        "\n",
        "        if len(coords) == 4:\n",
        "            # Ya es bounding box, se deja igual.\n",
        "            new_line = f\"{cls} {coords[0]:.16f} {coords[1]:.16f} {coords[2]:.16f} {coords[3]:.16f}\"\n",
        "        else:\n",
        "            # Es un polígono; se convierte a bounding box.\n",
        "            x_center, y_center, width, height = polygon_to_bbox(coords)\n",
        "            new_line = f\"{cls} {x_center:.16f} {y_center:.16f} {width:.16f} {height:.16f}\"      #puedes modificar el número de decimales(16, o los que quieras)\n",
        "        new_lines.append(new_line)\n",
        "\n",
        "    with open(dst_file, 'w') as f_out:\n",
        "        for new_line in new_lines:\n",
        "            f_out.write(new_line + \"\\n\")\n",
        "\n",
        "    print(f\"Procesado: {os.path.basename(src_file)} -> {os.path.basename(dst_file)}\")\n",
        "\n",
        "def process_all_labels(src_labels_dir, dst_labels_dir):\n",
        "    \"\"\"\n",
        "    Procesa todos los archivos .txt en src_labels_dir y guarda los nuevos archivos\n",
        "    (con anotaciones convertidas a bounding boxes) en dst_labels_dir.\n",
        "    \"\"\"\n",
        "    os.makedirs(dst_labels_dir, exist_ok=True)\n",
        "    for filename in os.listdir(src_labels_dir):\n",
        "        if filename.endswith(\".txt\"):\n",
        "            src_path = os.path.join(src_labels_dir, filename)\n",
        "            dst_path = os.path.join(dst_labels_dir, filename)\n",
        "            process_label_file(src_path, dst_path)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    ###############################################################################################33\n",
        "    # Rutas de entrada y salida: modifica estas rutas a las de tu sistema\n",
        "    src_labels_dir = \"E:/fotos_modelo_5000_fina/valid/labels\"\n",
        "    dst_labels_dir = \"E:/fotos_modelo_5000_fina/valid/valid_bbconverted_labels\"\n",
        "\n",
        "    ################################################################################################\n",
        "    process_all_labels(src_labels_dir, dst_labels_dir)\n",
        "\n",
        "    print(\"¡Conversión completada!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dDp9sjLMUdG-"
      },
      "source": [
        "#3) Comprobar que esas anotaciones que ha hecho, corresponden con las imágenes y están bien hechas\n",
        "\n",
        "SOLO UNA IMAGEN\n",
        "\n",
        "Saldrá la imagen con las anotaciones."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Zewe9JwIUdG-"
      },
      "outputs": [],
      "source": [
        "#import supervision, cv2 and numpy si lo necesitas en terminal, como antes: pip install supervision, cv2, numpy\n",
        "!pip install supervision\n",
        "!pip install cv2\n",
        "!pip install numpy\n",
        "import supervision as sv\n",
        "import cv2\n",
        "import numpy as np\n",
        "\n",
        "# Load the image\n",
        "image = cv2.imread(\"/content/drive/MyDrive/fotos_pruebas/resultados_bgr2/dataset_aug11/images/DSC02325_rotate.jpg\")\n",
        "\n",
        "# Load the labels from the txt file\n",
        "with open(\"/content/drive/MyDrive/fotos_pruebas/resultados_bgr2/dataset_aug11/labels/DSC02325_rotate.txt\", \"r\") as f:\n",
        "    lines = f.readlines()\n",
        "\n",
        "# Parse the labels\n",
        "xyxy = []\n",
        "confidence = []\n",
        "class_id = []\n",
        "for line in lines:\n",
        "    class_id_, x_center, y_center, width, height = map(float, line.strip().split())\n",
        "    x1 = (x_center - width/2) * image.shape[1]\n",
        "    y1 = (y_center - height/2) * image.shape[0]\n",
        "    x2 = (x_center + width/2) * image.shape[1]\n",
        "    y2 = (y_center + height/2) * image.shape[0]\n",
        "    xyxy.append([x1, y1, x2, y2])\n",
        "    confidence.append(1.0)  # Assuming confidence of 1.0 for all detections\n",
        "    class_id.append(class_id_)\n",
        "\n",
        "# Convert to supervision Detections object\n",
        "detections = sv.Detections(\n",
        "    xyxy=np.array(xyxy),\n",
        "    confidence=np.array(confidence),\n",
        "    class_id=np.array(class_id).astype(int)\n",
        ")\n",
        "\n",
        "# Create annotators\n",
        "box_annotator = sv.BoundingBoxAnnotator()\n",
        "label_annotator = sv.LabelAnnotator()\n",
        "\n",
        "# Annotate the image\n",
        "annotated_frame = box_annotator.annotate(scene=image.copy(), detections=detections)\n",
        "annotated_frame = label_annotator.annotate(scene=annotated_frame, detections=detections, labels=[f\"Class {int(class_id)}\" for class_id in detections.class_id])\n",
        "\n",
        "# Display the annotated image\n",
        "sv.plot_image(image=annotated_frame, size=(16, 16))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wvMADezUUdG-"
      },
      "source": [
        "#4. Tiling en carpetas grandes\n",
        "\n",
        "\n",
        "**    IMPORTANTE     **\n",
        "\n",
        "Aquí he de cambiar el tamaño de tiles que yo quierO"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y9VfdNh1UdG_"
      },
      "source": [
        "4.1 Generando todo en una carpeta    \n",
        "(también está el código para hacer subcarpetas de cada imagen con tiles y con txt)\n",
        "para cada imagen , partiendo de imagen y txt, crea tiles que van asociadas a txt, por lo tanto defines rutas entrada, salida y tamaño tiles"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L6_HlGTZUdG_"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import os\n",
        "import numpy as np\n",
        "\n",
        "def load_annotations(label_path, image_width, image_height):\n",
        "    \"\"\"\n",
        "    Lee el archivo de anotaciones en formato YOLO (bounding boxes o polígonos)\n",
        "    y devuelve una lista de anotaciones en coordenadas absolutas (en píxeles):\n",
        "    (cls, x1, y1, x2, y2)\n",
        "    \"\"\"\n",
        "    annotations = []\n",
        "    with open(label_path, 'r') as f:\n",
        "        for line in f:\n",
        "            parts = line.strip().split()\n",
        "            if not parts:\n",
        "                continue\n",
        "            cls = parts[0]\n",
        "            coords = list(map(float, parts[1:]))\n",
        "\n",
        "            if len(coords) == 4:\n",
        "                # Ya es bounding box (normalizada: x_center, y_center, w, h)\n",
        "                x_center, y_center, w, h = coords\n",
        "                abs_x_center = x_center * image_width\n",
        "                abs_y_center = y_center * image_height\n",
        "                abs_w = w * image_width\n",
        "                abs_h = h * image_height\n",
        "                x1 = abs_x_center - abs_w/2\n",
        "                y1 = abs_y_center - abs_h/2\n",
        "                x2 = abs_x_center + abs_w/2\n",
        "                y2 = abs_y_center + abs_h/2\n",
        "            else:\n",
        "                # Es un polígono: convertir a bounding box envolvente\n",
        "                xs = coords[0::2]\n",
        "                ys = coords[1::2]\n",
        "                x1 = min(xs) * image_width\n",
        "                x2 = max(xs) * image_width\n",
        "                y1 = min(ys) * image_height\n",
        "                y2 = max(ys) * image_height\n",
        "\n",
        "            annotations.append((cls, x1, y1, x2, y2))\n",
        "    return annotations\n",
        "\n",
        "def adjust_annotation_for_tile(annotation, tile_x, tile_y, tile_size):\n",
        "    \"\"\"\n",
        "    Dada una anotación en coordenadas absolutas (x1, y1, x2, y2) de la imagen original,\n",
        "    y el offset (tile_x, tile_y) del tile, calcula la intersección entre la caja y el tile.\n",
        "    Devuelve la bounding box transformada a coordenadas locales del tile (normalizadas)\n",
        "    o None si no hay intersección.\n",
        "    \"\"\"\n",
        "    cls, x1, y1, x2, y2 = annotation\n",
        "    tile_x1, tile_y1 = tile_x, tile_y\n",
        "    tile_x2, tile_y2 = tile_x + tile_size, tile_y + tile_size\n",
        "\n",
        "    # Calcular la intersección\n",
        "    inter_x1 = max(x1, tile_x1)\n",
        "    inter_y1 = max(y1, tile_y1)\n",
        "    inter_x2 = min(x2, tile_x2)\n",
        "    inter_y2 = min(y2, tile_y2)\n",
        "\n",
        "    if inter_x2 <= inter_x1 or inter_y2 <= inter_y1:\n",
        "        return None  # No hay intersección\n",
        "\n",
        "    # Convertir a coordenadas locales del tile\n",
        "    local_x1 = inter_x1 - tile_x\n",
        "    local_y1 = inter_y1 - tile_y\n",
        "    local_x2 = inter_x2 - tile_x\n",
        "    local_y2 = inter_y2 - tile_y\n",
        "\n",
        "    box_w = local_x2 - local_x1\n",
        "    box_h = local_y2 - local_y1\n",
        "    x_center = local_x1 + box_w / 2.0\n",
        "    y_center = local_y1 + box_h / 2.0\n",
        "    norm_x_center = x_center / tile_size\n",
        "    norm_y_center = y_center / tile_size\n",
        "    norm_w = box_w / tile_size\n",
        "    norm_h = box_h / tile_size\n",
        "\n",
        "    return (cls, norm_x_center, norm_y_center, norm_w, norm_h)\n",
        "\n",
        "def process_image_tiling(image_path, label_path, tile_size, output_images_dir, output_labels_dir, overlap=0):\n",
        "    \"\"\"\n",
        "    Realiza el tiling de una imagen y ajusta sus anotaciones.\n",
        "    Guarda cada tile en output_images_dir y su etiqueta correspondiente en output_labels_dir.\n",
        "    'overlap' (en píxeles) permite solapar los tiles.\n",
        "    \"\"\"\n",
        "    image = cv2.imread(image_path)\n",
        "    if image is None:\n",
        "        print(f\"Error al cargar {image_path}\")\n",
        "        return\n",
        "    orig_h, orig_w, _ = image.shape\n",
        "\n",
        "    annotations = load_annotations(label_path, orig_w, orig_h)\n",
        "\n",
        "    tile_idx = 0\n",
        "    # Iterar en el eje Y y X con el paso (tile_size - overlap)\n",
        "    step = tile_size - overlap\n",
        "    for y in range(0, orig_h, step):\n",
        "        for x in range(0, orig_w, step):\n",
        "            # Extraer tile de la imagen (puede ser más pequeño en bordes)\n",
        "            tile = image[y:min(y+tile_size, orig_h), x:min(x+tile_size, orig_w)]\n",
        "            tile_h, tile_w, _ = tile.shape\n",
        "            # Si el tile es menor, aplicar padding para que sea de tamaño tile_size x tile_size\n",
        "            if tile_h < tile_size or tile_w < tile_size:\n",
        "                padded_tile = np.zeros((tile_size, tile_size, 3), dtype=tile.dtype)\n",
        "                padded_tile[0:tile_h, 0:tile_w] = tile\n",
        "                tile = padded_tile\n",
        "\n",
        "            # Nombrar el tile usando el nombre original de la imagen y un índice\n",
        "            base_name = os.path.splitext(os.path.basename(image_path))[0]\n",
        "            tile_filename = f\"{base_name}_tile_{tile_idx}.jpg\"\n",
        "            cv2.imwrite(os.path.join(output_images_dir, tile_filename), tile)\n",
        "\n",
        "            # Ajustar las anotaciones para el tile\n",
        "            tile_annotations = []\n",
        "            for ann in annotations:\n",
        "                adj_ann = adjust_annotation_for_tile(ann, x, y, tile_size)\n",
        "                if adj_ann is not None:\n",
        "                    tile_annotations.append(adj_ann)\n",
        "\n",
        "            # Guardar la anotación del tile\n",
        "            label_filename = f\"{base_name}_tile_{tile_idx}.txt\"\n",
        "            with open(os.path.join(output_labels_dir, label_filename), \"w\") as f:\n",
        "                for ann in tile_annotations:\n",
        "                    cls, xc, yc, w, h = ann\n",
        "                    f.write(f\"{cls} {xc:.6f} {yc:.6f} {w:.6f} {h:.6f}\\n\")\n",
        "\n",
        "            tile_idx += 1\n",
        "    print(f\"Procesada {os.path.basename(image_path)}: {tile_idx} tiles generados.\")\n",
        "\n",
        "def process_dataset(source_images_dir, source_labels_dir, output_images_dir, output_labels_dir, tile_size=960, overlap=0):\n",
        "    \"\"\"\n",
        "    Procesa todas las imágenes en source_images_dir, buscando para cada una su .txt\n",
        "    en source_labels_dir. Guarda todos los tiles en output_images_dir y\n",
        "    todas las anotaciones en output_labels_dir.\n",
        "    \"\"\"\n",
        "    os.makedirs(output_images_dir, exist_ok=True)\n",
        "    os.makedirs(output_labels_dir, exist_ok=True)\n",
        "\n",
        "    image_files = [f for f in os.listdir(source_images_dir) if f.lower().endswith(('.jpg', '.jpeg', '.png'))]\n",
        "\n",
        "    for img_file in image_files:\n",
        "        image_path = os.path.join(source_images_dir, img_file)\n",
        "        label_file = os.path.splitext(img_file)[0] + \".txt\"\n",
        "        label_path = os.path.join(source_labels_dir, label_file)\n",
        "        if not os.path.exists(label_path):\n",
        "            print(f\"Advertencia: No se encontró etiqueta para {img_file}. Saltando...\")\n",
        "            continue\n",
        "        process_image_tiling(image_path, label_path, tile_size, output_images_dir, output_labels_dir, overlap=overlap)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # Rutas de ejemplo: ajusta estas rutas a las de tu sistema\n",
        "    source_images_dir = \"E:/fotos_modelo_5000_fina/test/images\"\n",
        "    source_labels_dir = \"E:/fotos_modelo_5000_fina/test/test_bbconverted_labels\"\n",
        "\n",
        "\n",
        "    # Directorios de salida unificados para tiles e anotaciones\n",
        "    output_images_dir = \"C:/Users/CABALLERO DE ROHAN/Desktop/new_model_640_labels/test/images\"\n",
        "    output_labels_dir = \"C:/Users/CABALLERO DE ROHAN/Desktop/new_model_640_labels/test/labels\"\n",
        "\n",
        "\n",
        "####################################################################################################################################################\n",
        "####################################################################################################################################################\n",
        "\n",
        "\n",
        "    # Parámetros: tile size y overlap (si quieres solapamiento, por ejemplo, 50 píxeles)\n",
        "\n",
        "    tile_size = 640\n",
        "    overlap = 50  # Puedes ajustar o poner 0 si no quieres solapamiento.  ## mejor solapamiento?  --> chatgp:  -->Sí, solapar (overlap) los tiles es una práctica común. Cuando un objeto (o una caja) cae justo en el borde de un tile, si no hay solapamiento existe el riesgo de que la caja se corte y se pierda parte de la información. Con un solapamiento, ese objeto puede aparecer (completamente o en mayor medida) en el tile adyacente. Esto mejora la probabilidad de que el objeto se detecte correctamente.\n",
        "\n",
        "\n",
        "####################################################################################################################################################\n",
        "####################################################################################################################################################\n",
        "\n",
        "    process_dataset(source_images_dir, source_labels_dir, output_images_dir, output_labels_dir, tile_size=tile_size, overlap=overlap)\n",
        "    print(\"Tiling de todas las imágenes completado.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pGTehi72UdHA"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.2"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}